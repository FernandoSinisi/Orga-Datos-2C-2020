{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 157.5 MB 21 kB/s  eta 0:00:01     |██▊                             | 13.2 MB 12.0 MB/s eta 0:00:13     |██▉                             | 13.9 MB 12.0 MB/s eta 0:00:12     |█████▏                          | 25.3 MB 553 kB/s eta 0:03:59     |████████▏                       | 40.0 MB 1.7 MB/s eta 0:01:09     |███████████▍                    | 56.0 MB 1.5 MB/s eta 0:01:06     |████████████████                | 78.6 MB 1.5 MB/s eta 0:00:54     |██████████████████▉             | 92.9 MB 1.3 MB/s eta 0:00:49     |███████████████████████████████▉| 156.8 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/violeta/.local/lib/python3.8/site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in /home/violeta/.local/lib/python3.8/site-packages (from xgboost) (1.5.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n",
      "Requirement already satisfied: category_encoders in /home/violeta/.local/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /home/violeta/.local/lib/python3.8/site-packages (from category_encoders) (0.12.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/violeta/.local/lib/python3.8/site-packages (from category_encoders) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/violeta/.local/lib/python3.8/site-packages (from category_encoders) (1.19.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/violeta/.local/lib/python3.8/site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/violeta/.local/lib/python3.8/site-packages (from category_encoders) (1.5.3)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/violeta/.local/lib/python3.8/site-packages (from category_encoders) (1.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/violeta/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/violeta/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.1->category_encoders) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas>=0.21.1->category_encoders) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=0.21.1->category_encoders) (2.7.3)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install xgboost\n",
    "! pip3 install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c6daa241a42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "import category_encoders\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino columnas vacios o con datos que no sirven\n",
    "\n",
    "train = df_train.drop(columns = ['Last_Activity','Actual_Delivery_Date','Price','Size','Product_Type','Brand'])\n",
    "#Filtro solo los registros que esten en estado finalizado y los convierto en valores binarios\n",
    "#Closed Won = 1 - Closed Lost = 0\n",
    "train = train[(train['Stage'] == 'Closed Won') | (train['Stage'] == 'Closed Lost')]\n",
    "train['Stage'] = train['Stage'].transform(func=lambda x : 1 if x=='Closed Won' else 0)\n",
    "train\n",
    "#ordeno por fecha de creacion de la oportunidad\n",
    "train[\"Opportunity_Created_Date\"] = pd.to_datetime(train[\"Opportunity_Created_Date\"])\n",
    "train.sort_values(\"Opportunity_Created_Date\",inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train[\"Stage\"].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.loc[:,[\"Pricing, Delivery_Terms_Quote_Appr\",\"Pricing, Delivery_Terms_Approved\",\"Bureaucratic_Code_0_Approval\",\\\n",
    "                       \"Bureaucratic_Code_0_Approved\",\"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\\\n",
    "                        \"Total_Amount\",\"Total_Taxable_Amount\",\"Stage\"]].fillna(0)\n",
    "\n",
    "features\n",
    "#hay datos nan que hacemos??\n",
    "#lo lleno de 0 momentaneamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Opp = train.loc[:,[\"Opportunity_ID\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount\",\"Total_Taxable_Amount\"]].fillna(0).groupby(\"Opportunity_ID\")\n",
    "meanOpp = Opp.transform(\"mean\").add_suffix(\"_Opp_Mean\")\n",
    "countOpp = Opp.transform(\"count\").loc[:,[\"TRF\"]].rename(columns={\"TRF\":\"Opp_Item_Count\"})\n",
    "features = features.join(meanOpp)\n",
    "features = features.join(countOpp)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = category_encoders.TargetEncoder(smoothing=True)\n",
    "#Ajusto el codificador usando la variable categórica y el objetivo\n",
    "tg.fit(train['Region'], train['Stage'])\n",
    "#Aplico la codificacion a la columna Region\n",
    "region_feature_encoded = tg.transform(train['Region'])\n",
    "#Guardo la columna en el dataframe de entrenamiento\n",
    "region = train.join(region_feature_encoded.add_suffix('_target_mean'))\n",
    "region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = category_encoders.TargetEncoder(smoothing=True)\n",
    "#Ajusto el codificador usando la variable categórica y el objetivo\n",
    "tg.fit(train['Territory'], train['Stage'])\n",
    "#Aplico la codificacion a la columna Region\n",
    "territory_feature_encoded = tg.transform(train['Territory'])\n",
    "#Guardo la columna en el dataframe de entrenamiento\n",
    "territory = train.join(territory_feature_encoded.add_suffix('_target_mean'))\n",
    "territory.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varios features con mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mean = [\"Region\",\"Territory\",\"Bureaucratic_Code\",\"Account_Type\",\"ASP_Currency\",\"Source \",\"Opportunity_Owner\",\"Account_Owner\"]\n",
    "\n",
    "for column in columns_mean:\n",
    "    tg_en = category_encoders.TargetEncoder(smoothing=True)\n",
    "    #Ajusto el codificador usando la variable categórica y el objetivo\n",
    "    tg_en.fit(train[column], train['Stage'])\n",
    "    #Aplico la codificacion a la columna\n",
    "    feature_encoded = tg_en.transform(train[column])\n",
    "    #Guardo la columna en el dataframe de entrenamiento\n",
    "    features = features.join(feature_encoded.add_suffix('_target_mean'))\n",
    "    \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"USD_ASP_Currency\"] = train['ASP_Currency'].transform(func=lambda x : 1 if x=='USD' else 0)\n",
    "features[\"EUR_ASP_Currency\"] = train['ASP_Currency'].transform(func=lambda x : 1 if x=='EUR' else 0)\n",
    "features[\"JPY_ASP_Currency\"] = train['ASP_Currency'].transform(func=lambda x : 1 if x=='JPY' else 0)\n",
    "features[\"AUD_ASP_Currency\"] = train['ASP_Currency'].transform(func=lambda x : 1 if x=='AUD' else 0)\n",
    "features[\"GBP_ASP_Currency\"] = train['ASP_Currency'].transform(func=lambda x : 1 if x=='GBP' else 0)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"Japan_Region\"] = train['Region'].transform(func=lambda x : 1 if x=='Japan' else 0)\n",
    "features[\"EMEA_Region\"] = train['Region'].transform(func=lambda x : 1 if x=='EMEA' else 0)\n",
    "features[\"Americas_Region\"] = train['Region'].transform(func=lambda x : 1 if x=='Americas' else 0)\n",
    "features[\"APAC_Region\"] = train['Region'].transform(func=lambda x : 1 if x=='APAC' else 0)\n",
    "features[\"Middle_East_Region\"] = train['Region'].transform(func=lambda x : 1 if x=='Middle East' else 0)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Region\",\"Territory\",\"Bureaucratic_Code\",\"Account_Type\",\"ASP_Currency\",\"Source \",\"Opportunity_Owner\",\"Account_Owner\"]\n",
    "\n",
    "for column in columns:\n",
    "    bi_en = category_encoders.BinaryEncoder()\n",
    "    #Ajusto el codificador usando la variable categórica y el objetivo\n",
    "    bi_en.fit(train[column], train['Stage'])\n",
    "    #Aplico la codificacion a la columna\n",
    "    feature_encoded = bi_en.transform(train[column])\n",
    "    #Guardo la columna en el dataframe de entrenamiento\n",
    "    features = features.join(feature_encoded.add_suffix('_target_binary_enc'))\n",
    "    \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#falta mas features basados en texto encodeados con tf-idf y otros\n",
    "# fechas ?? esta ordenado por fecha creacion de oportunidad, hay que poner columna de mes año dia, etc\n",
    "# analisis de los mejores features\n",
    "#hace falta encodear todos??\n",
    "#no sirven mucho los de one hot encoding\n",
    "# falta la mezcla de precios montos total trf\n",
    "# falta concatenar territorio y region y encodear\n",
    "#falta concatenar moneda con otros\n",
    "# vendedor y demas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features.to_csv('data/features.csv')\n",
    "features.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
