{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from numpy import sort\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mean_encoding = pd.read_csv('../Feature_Encoding/data/train_mean_encoding.csv')\n",
    "df_test_mean_encoding = pd.read_csv('../Feature_Encoding/data/test_mean_encoding.csv')\n",
    "df_train_binary_encoding = pd.read_csv('../Feature_Encoding/data/train_binary_encoding.csv')\n",
    "df_test_binary_encoding = pd.read_csv('../Feature_Encoding/data/test_binary_encoding.csv')\n",
    "train = pd.read_csv('../Feature_Engineering/data/other-cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, x_train, y_train):\n",
    "    score_cross_val = model_selection.cross_val_score(model, x_train, y_train, cv=5)\n",
    "    print(score_cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realiza busqueda completa combinando los parametros\n",
    "def xgboost(x_train, y_train, x_validation, y_validation):\n",
    "    xgb_classifier = XGBClassifier()\n",
    "    params_xgb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.05, 0.1], 'gamma': [0, 1, 5]}    \n",
    "    xgb_gs = GridSearchCV(xgb_classifier, params_xgb, cv=5)\n",
    "    xgb_gs.fit(x_train, y_train)\n",
    "    xgb_best = xgb_gs.best_estimator_\n",
    "    print(xgb_gs.best_params_)\n",
    "    print('xgb: {}'.format(xgb_best.score(x_validation, y_validation)))\n",
    "    return xgb_best\n",
    "\n",
    "\n",
    "#Realiza busqueda random dentro de los parametros validos\n",
    "def xgboost2(x_train, y_train, x_validation, y_validation):\n",
    "    xgb_classifier = XGBClassifier()\n",
    "    params_xgb_2={\n",
    "        'n_estimators':stats.randint(10,500),'learning_rate':stats.uniform(0.01,0.3),\n",
    "        'subsample':stats.uniform(0.3,0.7),'min_child_weight':[1,5,10],\n",
    "        'max_depth':[3,10,6],'gamma':stats.randint(0,10),'colsample_bytree':stats.uniform(0.,0.6)\n",
    "    }\n",
    "    \n",
    "    xgb_rs = RandomizedSearchCV(xgb.XGBClassifier(n_jobs=-1),\n",
    "                          param_distributions=params_xgb_2,\n",
    "                          cv=2,\n",
    "                          scoring='neg_log_loss',\n",
    "                          verbose=1,\n",
    "                          n_iter=200)\n",
    "    \n",
    "    xgb_rs.fit(x_train, y_train)\n",
    "    xgb_best = xgb_rs.best_estimator_\n",
    "    print(xgb_rs.best_params_)\n",
    "    print('xgb: {}'.format(xgb_best.score(x_validation, y_validation)))\n",
    "    return xgb_best\n",
    "\n",
    "def test_model(model, x_test, y_test):\n",
    "    predictions = model.predict_proba(x_test)[:,1]\n",
    "    logloss = log_loss(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions.round())\n",
    "    print(\"Accuracy: %.2f%%, Logloss: %.2f\" % (accuracy*100.0, logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Target\n",
    "x_train_mean_encoding, x_validation_mean_encoding, y_train_mean_encoding, y_validation_mean_encoding = train_test_split(df_train_mean_encoding, y, test_size=0.3, stratify=y)\n",
    "x_train_binary_encoding, x_validation_binary_encoding, y_train_binary_encoding, y_validation_binary_encoding = train_test_split(df_train_binary_encoding, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0, 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "xgb: 0.8923988153998026\n",
      "Accuracy: 89.24%, Logloss: 0.24\n",
      "0.8937210935939216\n"
     ]
    }
   ],
   "source": [
    "xgboost_mean_encoding = xgboost(x_train_mean_encoding, y_train_mean_encoding, x_validation_mean_encoding, y_validation_mean_encoding)\n",
    "test_model(xgboost_mean_encoding,x_validation_mean_encoding,y_validation_mean_encoding)\n",
    "cross_val(xgboost_mean_encoding, x_train_mean_encoding, y_train_mean_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 200 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed: 22.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.28630949913269416, 'gamma': 0, 'learning_rate': 0.0906709697875075, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 210, 'subsample': 0.9239971976963097}\n",
      "xgb: 0.9342546890424481\n",
      "Accuracy: 93.43%, Logloss: 0.16\n",
      "0.9273143921411094\n"
     ]
    }
   ],
   "source": [
    "xgboost_mean_encoding = xgboost2(x_train_mean_encoding, y_train_mean_encoding, x_validation_mean_encoding, y_validation_mean_encoding)\n",
    "test_model(xgboost_mean_encoding,x_validation_mean_encoding,y_validation_mean_encoding)\n",
    "cross_val(xgboost_mean_encoding, x_train_mean_encoding, y_train_mean_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "xgb: 0.8756169792694966\n",
      "Accuracy: 87.56%, Logloss: 0.29\n",
      "0.8710433981867954\n"
     ]
    }
   ],
   "source": [
    "xgboost_binary_encoding = xgboost(x_train_binary_encoding, y_train_binary_encoding, x_validation_binary_encoding, y_validation_binary_encoding)\n",
    "test_model(xgboost_binary_encoding,x_validation_binary_encoding,y_validation_binary_encoding)\n",
    "cross_val(xgboost_binary_encoding, x_train_binary_encoding, y_train_binary_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 200 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed: 55.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.20900672188191186, 'gamma': 1, 'learning_rate': 0.10874310026757804, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 487, 'subsample': 0.8846703276847963}\n",
      "xgb: 0.9251727541954591\n",
      "Accuracy: 92.52%, Logloss: 0.19\n",
      "0.9207137246309252\n"
     ]
    }
   ],
   "source": [
    "xgboost_binary_encoding = xgboost2(x_train_binary_encoding, y_train_binary_encoding, x_validation_binary_encoding, y_validation_binary_encoding)\n",
    "test_model(xgboost_binary_encoding,x_validation_binary_encoding,y_validation_binary_encoding)\n",
    "cross_val(xgboost_binary_encoding, x_train_binary_encoding, y_train_binary_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_mean_encoding.predict_proba(df_test_mean_encoding)[:,1]\n",
    "submission_xgboost = pd.DataFrame(data={'Opportunity_ID':df_test_mean_encoding['Opportunity_ID'], 'Target': y_pred})\n",
    "submission_xgboost = submission_xgboost.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_xgboost.to_csv('submits/mean_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_binary_encoding.predict_proba(df_test_binary_encoding)[:,1]\n",
    "submission_xgboost = pd.DataFrame(data={'Opportunity_ID':df_test_binary_encoding['Opportunity_ID'], 'Target': y_pred})\n",
    "submission_xgboost = submission_xgboost.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_xgboost.to_csv('submits/binary_xgboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
