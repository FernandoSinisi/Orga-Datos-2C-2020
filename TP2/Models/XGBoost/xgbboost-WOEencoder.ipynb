{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../Feature_Engineering/data/other-cleaned_train.csv')\n",
    "test = pd.read_csv('../../Feature_Engineering/data/other-cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "test.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_columns = train.drop(columns = [\"Opportunity_ID\",\"ID\", \"Pricing, Delivery_Terms_Quote_Appr\",\\\n",
    "                                    \"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\\\n",
    "                                    \"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount\",\\\n",
    "                                    \"Total_Taxable_Amount\",\"diferencia_en_dias\",\"Last_Modified_DOY\",\"Last_Modified_Year\",\\\n",
    "                                    \"Opportunity_Created_DOY\",\"Opportunity_Created_Year\",\"Quote_Expiry_DOY\",\\\n",
    "                                     \"Quote_Expiry_Year\",\"Planned_Delivery_Start_DOY\",\"Planned_Delivery_Start_Year\",\\\n",
    "                                    \"Planned_Delivery_End_DOY\",\"Planned_Delivery_End_Year\",\\\n",
    "                                    \"Target\"]).columns\n",
    "for column in categ_columns:\n",
    "    encoder = WOEEncoder()\n",
    "    encoder.fit(train[column], train['Target'])\n",
    "    feature_encoded = encoder.transform(train[column])\n",
    "    X_train = X_train.join(feature_encoded.add_suffix('_woe'))\n",
    "    X_train.drop(columns=[column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_columns = test.drop(columns = [\"Opportunity_ID\",\"ID\", \"Pricing, Delivery_Terms_Quote_Appr\",\\\n",
    "                                    \"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\\\n",
    "                                    \"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount\",\\\n",
    "                                    \"Total_Taxable_Amount\",\"diferencia_en_dias\",\"Last_Modified_DOY\",\"Last_Modified_Year\",\\\n",
    "                                    \"Opportunity_Created_DOY\",\"Opportunity_Created_Year\",\"Quote_Expiry_DOY\",\\\n",
    "                                     \"Quote_Expiry_Year\",\"Planned_Delivery_Start_DOY\",\"Planned_Delivery_Start_Year\",\\\n",
    "                                    \"Planned_Delivery_End_DOY\",\"Planned_Delivery_End_Year\"]).columns\n",
    "for column in categ_columns:\n",
    "    encoder = WOEEncoder()\n",
    "    encoder.fit(train[column], train['Target'])\n",
    "    feature_encoded = encoder.transform(test[column])\n",
    "    X_test = X_test.join(feature_encoded.add_suffix('_woe'))\n",
    "    X_test.drop(columns=[column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Total_Amount\"] = pd.to_numeric(X_train[\"Total_Amount\"],errors='coerce').fillna(X_train[\"Total_Amount\"].mean())\n",
    "X_train[\"Opportunity_Created_Year\"] = pd.to_numeric(X_train[\"Opportunity_Created_Year\"],errors='coerce').fillna(0)\n",
    "X_train[\"Quote_Expiry_DOY\"] = pd.to_numeric(X_train[\"Quote_Expiry_DOY\"],errors='coerce').fillna(0)\n",
    "X_train[\"Quote_Expiry_Year\"] = pd.to_numeric(X_train[\"Quote_Expiry_Year\"],errors='coerce').fillna(0)\n",
    "X_train[\"Planned_Delivery_End_DOY\"] = pd.to_numeric(X_train[\"Planned_Delivery_End_DOY\"],errors='coerce').fillna(0)\n",
    "X_train[\"Planned_Delivery_End_Year\"] = pd.to_numeric(X_train[\"Planned_Delivery_End_Year\"],errors='coerce').fillna(0)\n",
    "\n",
    "X_train = X_train.drop(columns = 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"Total_Amount\"] = pd.to_numeric(X_test[\"Total_Amount\"],errors='coerce').fillna(test[\"Total_Amount\"].mean())\n",
    "X_test[\"Opportunity_Created_Year\"] = pd.to_numeric(X_test[\"Opportunity_Created_Year\"],errors='coerce').fillna(0)\n",
    "X_test[\"Quote_Expiry_DOY\"] = pd.to_numeric(X_test[\"Quote_Expiry_DOY\"],errors='coerce').fillna(0)\n",
    "X_test[\"Quote_Expiry_Year\"] = pd.to_numeric(X_test[\"Quote_Expiry_Year\"],errors='coerce').fillna(0)\n",
    "X_test[\"Planned_Delivery_End_DOY\"] = pd.to_numeric(X_test[\"Planned_Delivery_End_DOY\"],errors='coerce').fillna(0)\n",
    "X_test[\"Planned_Delivery_End_Year\"] = pd.to_numeric(X_test[\"Planned_Delivery_End_Year\"],errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, x_train, y_train):\n",
    "    score_cross_val = model_selection.cross_val_score(model, x_train, y_train, cv=5)\n",
    "    print(score_cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(x_train, y_train, x_validation, y_validation):\n",
    "    xgb_classifier = XGBClassifier()\n",
    "    params_xgb = {'n_estimators': [50,75,100], 'learning_rate': [0.01, 0.05, 0.1], 'gamma': [0, 1, 5],'max_depth':[3,10,6,15]}    \n",
    "    xgb_gs = GridSearchCV(xgb_classifier, params_xgb, cv=2)\n",
    "    xgb_gs.fit(x_train, y_train)\n",
    "    xgb_best = xgb_gs.best_estimator_\n",
    "    print(xgb_gs.best_params_)\n",
    "    print('xgb: {}'.format(xgb_best.score(x_validation, y_validation)))\n",
    "    return xgb_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost2(x_train, y_train, x_validation, y_validation):\n",
    "    params_xgb_2={\n",
    "        'n_estimators':stats.randint(10,300),'learning_rate':stats.uniform(0.01,0.3),\n",
    "        'subsample':stats.uniform(0.3,0.7),'min_child_weight':[1,5,10],\n",
    "        'max_depth':[3,10,6,15],'gamma':stats.randint(0,10),'colsample_bytree':stats.uniform(0.,0.6)\n",
    "    }\n",
    "    \n",
    "    xgb_rs = RandomizedSearchCV(xgb.XGBClassifier(n_jobs=-1),\n",
    "                          param_distributions=params_xgb_2,\n",
    "                          cv=2,\n",
    "                          scoring='neg_log_loss',\n",
    "                          verbose=1,\n",
    "                          n_iter=150)\n",
    "    \n",
    "    xgb_rs.fit(x_train, y_train)\n",
    "    xgb_best = xgb_rs.best_estimator_\n",
    "    print(xgb_rs.best_params_)\n",
    "    print('xgb: {}'.format(xgb_best.score(x_validation, y_validation)))\n",
    "    return xgb_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    predictions = model.predict_proba(x_test)[:,1]\n",
    "    logloss = log_loss(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions.round())\n",
    "    print(\"Accuracy: %.2f%%, Logloss: %.2f\" % (accuracy*100.0, logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_features(model,train):\n",
    "    importance = model.feature_importances_\n",
    "    result = pd.DataFrame([train.columns,importance]).transpose()\n",
    "    result.columns = [\"Feature\",\"Importance\"]\n",
    "    return result.sort_values(by='Importance', ascending=False).head(15)[\"Feature\"].to_list()\n",
    "    \n",
    "    \n",
    "def plot_features(model,train):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(350, 350)\n",
    "    selection = SelectFromModel(model, threshold=0.040, prefit=True)\n",
    "    selected_dataset = selection.transform(train)\n",
    "    model.plot_importance(booster=model)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,20)\n",
    "    plt.xlabel(\"\\nFeature importance\", fontsize=40)\n",
    "    plt.ylabel(\"Features\", fontsize=35)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb 1 with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Target\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X_train, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "xgb: 0.9293188548864758\n",
      "Accuracy: 92.93%, Logloss: 0.18\n",
      "0.9251147305505849\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgboost(x_train, y_train, x_validation, y_validation)\n",
    "test_model(xgb_model,x_validation,y_validation)\n",
    "cross_val(xgb_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = best_features(xgb_model,X_train)\n",
    "if \"Opportunity_ID\" not in best_features: \n",
    "    best_features.append(\"Opportunity_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict_proba(X_test)[:,1]\n",
    "submission_xgb = pd.DataFrame(data={'Opportunity_ID':X_test['Opportunity_ID'], 'Target': y_pred})\n",
    "submission_xgb = submission_xgb.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_xgb.to_csv('../submits/xgb_with_woe_encoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb 1 with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_best_features = X_train.loc[:,best_features]\n",
    "X_test_best_features = X_test.loc[:,best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_best_train, x_best_validation, y_best_train, y_best_validation = train_test_split(X_train_best_features, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0, 'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100}\n",
      "xgb: 0.9249753208292202\n",
      "Accuracy: 92.50%, Logloss: 0.19\n",
      "0.9167370194617671\n"
     ]
    }
   ],
   "source": [
    "xgb_model_2 = xgboost(x_best_train, y_best_train, x_best_validation, y_best_validation)\n",
    "test_model(xgb_model_2,x_best_validation,y_best_validation)\n",
    "cross_val(xgb_model_2, x_best_train, y_best_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = xgb_model_2.predict_proba(X_test_best_features)[:,1]\n",
    "submission_xgb_2 = pd.DataFrame(data={'Opportunity_ID':X_test_best_features['Opportunity_ID'], 'Target': y_pred_2})\n",
    "submission_xgb_2 = submission_xgb_2.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_xgb_2.to_csv('../submits/xgb_best_features_woe_encoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb boost 2 with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 150 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5674542619617974, 'gamma': 4, 'learning_rate': 0.07217205748199952, 'max_depth': 15, 'min_child_weight': 1, 'n_estimators': 225, 'subsample': 0.9088612748963232}\n",
      "xgb: 0.9255676209279369\n",
      "Accuracy: 92.56%, Logloss: 0.18\n",
      "0.92282978633516\n"
     ]
    }
   ],
   "source": [
    "xgb_model_3 = xgboost2(x_train, y_train, x_validation, y_validation)\n",
    "test_model(xgb_model_3,x_validation,y_validation)\n",
    "cross_val(xgb_model_3, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_2 = best_features(xgb_model_3,X_train)\n",
    "if \"Opportunity_ID\" not in best_features_2: \n",
    "    best_features_2.append(\"Opportunity_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3 = xgb_model_3.predict_proba(X_test)[:,1]\n",
    "submission_xgb_3 = pd.DataFrame(data={'Opportunity_ID':X_test['Opportunity_ID'], 'Target': y_pred_3})\n",
    "submission_xgb_3 = submission_xgb_3.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_xgb_3.to_csv('../submits/xgb_2_with_woe_encoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb  2 with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_best_features_2 = X_train.loc[:,best_features_2]\n",
    "X_test_best_features_2 = X_test.loc[:,best_features_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_best_train_2, x_best_validation_2, y_best_train_2, y_best_validation_2 = train_test_split(X_train_best_features_2, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 150 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.4070202587614009, 'gamma': 3, 'learning_rate': 0.16589516205536506, 'max_depth': 15, 'min_child_weight': 1, 'n_estimators': 114, 'subsample': 0.8773801786765878}\n",
      "xgb: 0.9062191510365252\n",
      "Accuracy: 90.62%, Logloss: 0.22\n",
      "0.9081061457194352\n"
     ]
    }
   ],
   "source": [
    "xgb_model_4 = xgboost2(x_best_train_2, y_best_train_2, x_best_validation_2, y_best_validation_2)\n",
    "test_model(xgb_model_4,x_best_validation_2,y_best_validation_2)\n",
    "cross_val(xgb_model_4, x_best_train_2, y_best_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_4 = xgb_model_4.predict_proba(X_test_best_features_2)[:,1]\n",
    "submission_xgb_4 = pd.DataFrame(data={'Opportunity_ID':X_test_best_features_2['Opportunity_ID'], 'Target': y_pred_4})\n",
    "submission_xgb_4 = submission_xgb_4.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_xgb_4.to_csv('../submits/xgb_2_best_features_with_woe_encoding.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
