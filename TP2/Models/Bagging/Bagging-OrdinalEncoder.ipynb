{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../Feature_Engineering/data/other-cleaned_train.csv')\n",
    "test = pd.read_csv('../../Feature_Engineering/data/other-cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "test.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_columns = train.drop(columns = [\"Opportunity_ID\",\"ID\", \"Pricing, Delivery_Terms_Quote_Appr\",\\\n",
    "                                    \"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\\\n",
    "                                    \"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount\",\\\n",
    "                                    \"Total_Taxable_Amount\",\"diferencia_en_dias\",\"Last_Modified_DOY\",\"Last_Modified_Year\",\\\n",
    "                                    \"Opportunity_Created_DOY\",\"Opportunity_Created_Year\",\"Quote_Expiry_DOY\",\\\n",
    "                                     \"Quote_Expiry_Year\",\"Planned_Delivery_Start_DOY\",\"Planned_Delivery_Start_Year\",\\\n",
    "                                    \"Planned_Delivery_End_DOY\",\"Planned_Delivery_End_Year\",\\\n",
    "                                    \"Target\"]).columns\n",
    "for column in categ_columns:\n",
    "    encoder = OrdinalEncoder()\n",
    "    encoder.fit(train[column], train['Target'])\n",
    "    feature_encoded = encoder.transform(train[column])\n",
    "    X_train = X_train.join(feature_encoded.add_suffix('_ordinal'))\n",
    "    X_train.drop(columns=[column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_columns = test.drop(columns = [\"Opportunity_ID\",\"ID\", \"Pricing, Delivery_Terms_Quote_Appr\",\\\n",
    "                                    \"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\\\n",
    "                                    \"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount\",\\\n",
    "                                    \"Total_Taxable_Amount\",\"diferencia_en_dias\",\"Last_Modified_DOY\",\"Last_Modified_Year\",\\\n",
    "                                    \"Opportunity_Created_DOY\",\"Opportunity_Created_Year\",\"Quote_Expiry_DOY\",\\\n",
    "                                     \"Quote_Expiry_Year\",\"Planned_Delivery_Start_DOY\",\"Planned_Delivery_Start_Year\",\\\n",
    "                                    \"Planned_Delivery_End_DOY\",\"Planned_Delivery_End_Year\"]).columns\n",
    "for column in categ_columns:\n",
    "    encoder = OrdinalEncoder()\n",
    "    encoder.fit(train[column], train['Target'])\n",
    "    feature_encoded = encoder.transform(test[column])\n",
    "    X_test = X_test.join(feature_encoded.add_suffix('_ordinal'))\n",
    "    X_test.drop(columns=[column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Total_Amount\"] = pd.to_numeric(X_train[\"Total_Amount\"],errors='coerce').fillna(X_train[\"Total_Amount\"].mean())\n",
    "X_train[\"Opportunity_Created_Year\"] = pd.to_numeric(X_train[\"Opportunity_Created_Year\"],errors='coerce').fillna(0)\n",
    "X_train[\"Quote_Expiry_DOY\"] = pd.to_numeric(X_train[\"Quote_Expiry_DOY\"],errors='coerce').fillna(0)\n",
    "X_train[\"Quote_Expiry_Year\"] = pd.to_numeric(X_train[\"Quote_Expiry_Year\"],errors='coerce').fillna(0)\n",
    "X_train[\"Planned_Delivery_End_DOY\"] = pd.to_numeric(X_train[\"Planned_Delivery_End_DOY\"],errors='coerce').fillna(0)\n",
    "X_train[\"Planned_Delivery_End_Year\"] = pd.to_numeric(X_train[\"Planned_Delivery_End_Year\"],errors='coerce').fillna(0)\n",
    "\n",
    "X_train = X_train.drop(columns = 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"Total_Amount\"] = pd.to_numeric(X_test[\"Total_Amount\"],errors='coerce').fillna(test[\"Total_Amount\"].mean())\n",
    "X_test[\"Opportunity_Created_Year\"] = pd.to_numeric(X_test[\"Opportunity_Created_Year\"],errors='coerce').fillna(0)\n",
    "X_test[\"Quote_Expiry_DOY\"] = pd.to_numeric(X_test[\"Quote_Expiry_DOY\"],errors='coerce').fillna(0)\n",
    "X_test[\"Quote_Expiry_Year\"] = pd.to_numeric(X_test[\"Quote_Expiry_Year\"],errors='coerce').fillna(0)\n",
    "X_test[\"Planned_Delivery_End_DOY\"] = pd.to_numeric(X_test[\"Planned_Delivery_End_DOY\"],errors='coerce').fillna(0)\n",
    "X_test[\"Planned_Delivery_End_Year\"] = pd.to_numeric(X_test[\"Planned_Delivery_End_Year\"],errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, x_train, y_train):\n",
    "    score_cross_val = model_selection.cross_val_score(model, x_train, y_train, cv=5)\n",
    "    print(score_cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(x_train, y_train, x_validation, y_validation):\n",
    "    bag_classifier = BaggingClassifier(DecisionTreeClassifier())\n",
    "    params_bag = {'n_estimators':[1,2,3,5,8,9,10,15,20],'max_samples':[1.0],'max_features':[1.0]}    \n",
    "    bag_gs = GridSearchCV(bag_classifier, params_bag, cv=3)\n",
    "    bag_gs.fit(x_train, y_train)\n",
    "    bag_best = bag_gs.best_estimator_\n",
    "    print(bag_gs.best_params_)\n",
    "    print('bag: {}'.format(bag_best.score(x_validation, y_validation)))\n",
    "    return bag_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    predictions = model.predict_proba(x_test)[:,1]\n",
    "    logloss = log_loss(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions.round())\n",
    "    print(\"Accuracy: %.2f%%, Logloss: %.2f\" % (accuracy*100.0, logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_features(model,train):\n",
    "    importance = np.mean([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "    result = pd.DataFrame([train.columns,importance]).transpose()\n",
    "    result.columns = [\"Feature\",\"Importance\"]\n",
    "    return result.sort_values(by='Importance', ascending=False).head(50)[\"Feature\"]\n",
    "    \n",
    "    \n",
    "def plot_features(model,train):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(350, 350)\n",
    "    selection = SelectFromModel(model, threshold=0.040, prefit=True)\n",
    "    selected_dataset = selection.transform(train)\n",
    "    model.plot_importance(booster=model)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,20)\n",
    "    plt.xlabel(\"\\nFeature importance\", fontsize=40)\n",
    "    plt.ylabel(\"Features\", fontsize=35)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Target\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X_train, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 15}\n",
      "bag: 0.8906219151036525\n",
      "Accuracy: 89.06%, Logloss: 0.45\n",
      "0.9004905720093976\n"
     ]
    }
   ],
   "source": [
    "bagging_model = bagging(x_train, y_train, x_validation, y_validation)\n",
    "test_model(bagging_model,x_validation,y_validation)\n",
    "cross_val(bagging_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = best_features(bagging_model,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bagging_model.predict_proba(X_test)[:,1]\n",
    "submission_bag = pd.DataFrame(data={'Opportunity_ID':X_test['Opportunity_ID'], 'Target': y_pred})\n",
    "submission_bag = submission_bag.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_bag.to_csv('../submits/bagging_ordinal_encoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_best_features = X_train.loc[:,best_features]\n",
    "X_test_best_features = X_test.loc[:,best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_best_train, x_best_validation, y_best_train, y_best_validation = train_test_split(X_train_best_features, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 15}\n",
      "bag: 0.8953603158933859\n",
      "Accuracy: 89.54%, Logloss: 0.43\n",
      "0.9039605938420359\n"
     ]
    }
   ],
   "source": [
    "bagging_model_2 = bagging(x_best_train, y_best_train, x_best_validation, y_best_validation)\n",
    "test_model(bagging_model_2,x_best_validation,y_best_validation)\n",
    "cross_val(bagging_model_2, x_best_train, y_best_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = bagging_model_2.predict_proba(X_test_best_features)[:,1]\n",
    "submission_bag_2 = pd.DataFrame(data={'Opportunity_ID':X_test_best_features['Opportunity_ID'], 'Target': y_pred_2})\n",
    "submission_bag_2 = submission_bag_2.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_bag_2.to_csv('../submits/bagging_best_features_ordinal_encoding_.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
