{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, accuracy_score, make_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from keras.models import Sequential, Input\n",
    "from keras.layers import  Dropout, Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mean_encoding = pd.read_csv('../../Feature_Encoding/data/train_mean_encoding.csv')\n",
    "df_test_mean_encoding = pd.read_csv('../../Feature_Encoding/data/test_mean_encoding.csv')\n",
    "train = pd.read_csv('../../Feature_Engineering/data/other-cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, x_train, y_train):\n",
    "    score_cross_val = model_selection.cross_val_score(model, x_train, y_train, cv=5)\n",
    "    print(score_cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal profunda - https://keras.io/guides/sequential_model/\n",
    "# nFeatures -> cantidad de features (columnas de set)\n",
    "# nClasses -> cantidad de clases que pueden ser (2 -> lost vs won)\n",
    "def DNN_model_bin(optimizer='rmsprop',init='glorot_uniform'):\n",
    "    node = 512\n",
    "    nClasses = 2\n",
    "    dropout=0.5\n",
    "    nFeatures = 185\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(node,input_dim=nFeatures,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,4):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# Red neuronal profunda - https://keras.io/guides/sequential_model/\n",
    "# nFeatures -> cantidad de features (columnas de set)\n",
    "# nClasses -> cantidad de clases que pueden ser (2 -> lost vs won)\n",
    "def DNN_model(optimizer='rmsprop',init='glorot_uniform'):\n",
    "    node = 512\n",
    "    nClasses = 2\n",
    "    dropout=0.5\n",
    "    nFeatures = 55\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(node,input_dim=nFeatures,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,4):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(x_train, y_train, x_validation, y_validation):\n",
    "    keras_model = KerasClassifier(build_fn=DNN_model)\n",
    "    optimizers = ['rmsprop', 'adam']\n",
    "    init = ['glorot_uniform', 'normal', 'uniform']\n",
    "    epochs = [50, 100, 150]\n",
    "    batches = batches = [5, 10, 20]\n",
    "    param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "    dnn_gs = GridSearchCV(keras_model, param_grid=param_grid)\n",
    "    dnn_gs.fit(x_train, y_train)\n",
    "    dnn_best = dnn_gs.best_estimator_\n",
    "    print(dnn_gs.best_params_)\n",
    "    print('dnn: {}'.format(dnn_best.score(x_validation, y_validation)))\n",
    "    return dnn_best\n",
    "\n",
    "def dnn_bin(x_train, y_train, x_validation, y_validation):\n",
    "    keras_model = KerasClassifier(build_fn=DNN_model_bin)\n",
    "    optimizers = ['rmsprop', 'adam']\n",
    "    init = ['glorot_uniform', 'normal', 'uniform']\n",
    "    epochs = [50, 100, 150]\n",
    "    batches = batches = [5, 10, 20]\n",
    "    param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "    dnn_gs = GridSearchCV(keras_model, param_grid=param_grid)\n",
    "    dnn_gs.fit(x_train, y_train)\n",
    "    dnn_best = dnn_gs.best_estimator_\n",
    "    print(dnn_gs.best_params_)\n",
    "    print('dnn: {}'.format(dnn_best.score(x_validation, y_validation)))\n",
    "    return dnn_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    predictions = model.predict_proba(x_test)[:,1]\n",
    "    logloss = log_loss(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions.round())\n",
    "    print(\"Accuracy: %.2f%%, Logloss: %.2f\" % (accuracy*100.0, logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Target\n",
    "x_train_mean_encoding, x_validation_mean_encoding, y_train_mean_encoding, y_validation_mean_encoding = train_test_split(df_train_mean_encoding, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 20s 10ms/step - loss: 88887.5723 - accuracy: 0.5195\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 1585.6469 - accuracy: 0.5203\n",
      "1891/1891 [==============================] - 35s 18ms/step - loss: 42911.7875 - accuracy: 0.5169\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 3858.3279 - accuracy: 0.5283\n",
      "1891/1891 [==============================] - 40s 21ms/step - loss: 80591.0868 - accuracy: 0.5291\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 1690.8616 - accuracy: 0.6409\n",
      "1891/1891 [==============================] - 35s 18ms/step - loss: 59474.5395 - accuracy: 0.5075\n",
      "473/473 [==============================] - 2s 5ms/step - loss: 77.5484 - accuracy: 0.5793\n",
      "1891/1891 [==============================] - 33s 17ms/step - loss: 52469.3516 - accuracy: 0.5392\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 625.4616 - accuracy: 0.5696\n",
      "1891/1891 [==============================] - 44s 23ms/step - loss: 39146.1102 - accuracy: 0.5114\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 355.2506 - accuracy: 0.5918\n",
      "1891/1891 [==============================] - 35s 18ms/step - loss: 77357.5884 - accuracy: 0.5252\n",
      "473/473 [==============================] - 2s 5ms/step - loss: 818.4391 - accuracy: 0.5656\n",
      "1891/1891 [==============================] - 34s 18ms/step - loss: 86427.4458 - accuracy: 0.5283\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 3106.2207 - accuracy: 0.6286\n",
      "1891/1891 [==============================] - 38s 20ms/step - loss: 86483.2625 - accuracy: 0.5253\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 276.8217 - accuracy: 0.6708\n",
      "1891/1891 [==============================] - 33s 17ms/step - loss: 50123.1183 - accuracy: 0.5215\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 3172.3701 - accuracy: 0.6449\n",
      "1891/1891 [==============================] - 69s 36ms/step - loss: 69272.6375 - accuracy: 0.5229\n",
      "473/473 [==============================] - 5s 9ms/step - loss: 3604.2588 - accuracy: 0.4353 3s - loss: 490\n",
      "1891/1891 [==============================] - 67s 35ms/step - loss: 61748.5493 - accuracy: 0.5346\n",
      "473/473 [==============================] - 4s 8ms/step - loss: 1861.2388 - accuracy: 0.6117\n",
      "1891/1891 [==============================] - 62s 32ms/step - loss: 61515.6548 - accuracy: 0.5245\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 1412.4680 - accuracy: 0.6662\n",
      "1891/1891 [==============================] - 60s 31ms/step - loss: 56489.0911 - accuracy: 0.5098\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 4286.7476 - accuracy: 0.5476\n",
      "1891/1891 [==============================] - 60s 31ms/step - loss: 54175.9631 - accuracy: 0.5163\n",
      "473/473 [==============================] - 3s 7ms/step - loss: 3725.3186 - accuracy: 0.5637\n",
      "1891/1891 [==============================] - 64s 33ms/step - loss: 60239.9939 - accuracy: 0.5217\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 226.3246 - accuracy: 0.5402\n",
      "1891/1891 [==============================] - 61s 32ms/step - loss: 96870.2321 - accuracy: 0.5157\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 443.5753 - accuracy: 0.5816\n",
      "1891/1891 [==============================] - 61s 32ms/step - loss: 76033.7628 - accuracy: 0.5031\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 1178.7007 - accuracy: 0.6565\n",
      "1891/1891 [==============================] - 61s 32ms/step - loss: 53578.8046 - accuracy: 0.5137\n",
      "473/473 [==============================] - 3s 7ms/step - loss: 310.3311 - accuracy: 0.6606\n",
      "1891/1891 [==============================] - 60s 31ms/step - loss: 83509.0627 - accuracy: 0.5163\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 377.8138 - accuracy: 0.5696\n",
      "1891/1891 [==============================] - 58s 30ms/step - loss: 74965.9290 - accuracy: 0.5145\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 5586.9551 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 58s 30ms/step - loss: 56614.4455 - accuracy: 0.5333\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 15698.8379 - accuracy: 0.5571\n",
      "1891/1891 [==============================] - 57s 30ms/step - loss: 52817.8224 - accuracy: 0.5181\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 1429.5760 - accuracy: 0.5842\n",
      "1891/1891 [==============================] - 58s 30ms/step - loss: 64500.2704 - accuracy: 0.5328\n",
      "473/473 [==============================] - 3s 7ms/step - loss: 1973.4530 - accuracy: 0.5476\n",
      "1891/1891 [==============================] - 57s 30ms/step - loss: 90767.9623 - accuracy: 0.5182\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 85.6291 - accuracy: 0.6551\n",
      "1891/1891 [==============================] - 58s 30ms/step - loss: 71464.2426 - accuracy: 0.5116\n",
      "473/473 [==============================] - 3s 7ms/step - loss: 19827.1699 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 59s 30ms/step - loss: 61100.1668 - accuracy: 0.5245\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 7969.6060 - accuracy: 0.6091\n",
      "1891/1891 [==============================] - 53s 27ms/step - loss: 77065.5454 - accuracy: 0.5270\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 1485.2101 - accuracy: 0.6726\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 74416.2285 - accuracy: 0.5101\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 182.8987 - accuracy: 0.6678\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 129867.8770 - accuracy: 0.5125\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 4371.7275 - accuracy: 0.6851\n",
      "1891/1891 [==============================] - 53s 27ms/step - loss: 68818.8798 - accuracy: 0.5225\n",
      "473/473 [==============================] - 3s 7ms/step - loss: 1764.9463 - accuracy: 0.4564\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 82816.3634 - accuracy: 0.5175\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 3488.4414 - accuracy: 0.6155\n",
      "1891/1891 [==============================] - 54s 28ms/step - loss: 55154.5759 - accuracy: 0.5106\n",
      "473/473 [==============================] - 4s 6ms/step - loss: 694.5738 - accuracy: 0.6624\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 69516.5676 - accuracy: 0.5203\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 6396.6709 - accuracy: 0.5476\n",
      "1891/1891 [==============================] - 53s 27ms/step - loss: 76976.3951 - accuracy: 0.5081\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 2697.1785 - accuracy: 0.5810\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 46155.4715 - accuracy: 0.5181\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 3094.9246 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 60s 31ms/step - loss: 109202.0651 - accuracy: 0.5311\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 2833.0562 - accuracy: 0.6311\n",
      "1891/1891 [==============================] - 54s 28ms/step - loss: 45057.8798 - accuracy: 0.5191\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 731.4276 - accuracy: 0.6688\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 99408.0050 - accuracy: 0.5074\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 932.2527 - accuracy: 0.6737\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 74781.0947 - accuracy: 0.5287\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 911.0534 - accuracy: 0.6784\n",
      "1891/1891 [==============================] - 55s 28ms/step - loss: 46684.4510 - accuracy: 0.5109\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 1335.5146 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 54s 28ms/step - loss: 96958.7512 - accuracy: 0.5129\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1156.3149 - accuracy: 0.6354\n",
      "1891/1891 [==============================] - 53s 27ms/step - loss: 41843.7534 - accuracy: 0.5127\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1091.3331 - accuracy: 0.5588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 51s 27ms/step - loss: 68536.1117 - accuracy: 0.5288\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 6816.5000 - accuracy: 0.4710\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 65983.9876 - accuracy: 0.5205\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 2344.0322 - accuracy: 0.6818\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 51316.8766 - accuracy: 0.5092\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1352.7855 - accuracy: 0.6417\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 59869.5530 - accuracy: 0.5172\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 10597.6992 - accuracy: 0.5571\n",
      "1891/1891 [==============================] - 53s 27ms/step - loss: 86720.0210 - accuracy: 0.5262\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 15320.1230 - accuracy: 0.5842\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 73959.0738 - accuracy: 0.5147\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 3518.9758 - accuracy: 0.4524\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 65477.1847 - accuracy: 0.5091\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 820.1166 - accuracy: 0.5552\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 49790.6813 - accuracy: 0.5165\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 179.0047 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 94074.2113 - accuracy: 0.5141\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 4905.5586 - accuracy: 0.5571\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 56609.5140 - accuracy: 0.5187\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1228.2117 - accuracy: 0.5787\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 89515.9719 - accuracy: 0.5188\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 2429.4749 - accuracy: 0.5946\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 52917.1435 - accuracy: 0.5281\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 5334.9795 - accuracy: 0.5696\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 122174.7601 - accuracy: 0.5206\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 3982.5720 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 64701.7330 - accuracy: 0.5213\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1547.4614 - accuracy: 0.6121\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 79446.1108 - accuracy: 0.5236\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 2187.0337 - accuracy: 0.6713\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 71118.2321 - accuracy: 0.5099\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 3374.3008 - accuracy: 0.4524\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 59300.4867 - accuracy: 0.5133\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 7380.6484 - accuracy: 0.4401\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 47915.1585 - accuracy: 0.5277\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 2243.1841 - accuracy: 0.6227\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 56959.3873 - accuracy: 0.5089\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1148.1008 - accuracy: 0.6083\n",
      "1891/1891 [==============================] - 53s 27ms/step - loss: 70223.2433 - accuracy: 0.5181\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1413.2074 - accuracy: 0.6701\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 73488.7276 - accuracy: 0.5240\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1265.3391 - accuracy: 0.5963\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 55982.2319 - accuracy: 0.5185\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 2774.5203 - accuracy: 0.6361\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 65612.4027 - accuracy: 0.5047\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1305.5187 - accuracy: 0.5791\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 104490.5869 - accuracy: 0.5267\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 22699.7910 - accuracy: 0.5571\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 69272.0406 - accuracy: 0.5310\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 124.6226 - accuracy: 0.5842\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 60516.2588 - accuracy: 0.5240\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 167.5511 - accuracy: 0.5476\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 53238.8621 - accuracy: 0.5139\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1834.1973 - accuracy: 0.5696\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 50023.3025 - accuracy: 0.5167\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 339.4504 - accuracy: 0.6083\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 70289.3230 - accuracy: 0.5244\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 668.4902 - accuracy: 0.6785\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 64704.7721 - accuracy: 0.5403\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 17552.3379 - accuracy: 0.5842\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 65431.7136 - accuracy: 0.5007\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 1575.8658 - accuracy: 0.6166\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 104700.6088 - accuracy: 0.5226\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 8431.5400 - accuracy: 0.5696\n",
      "1891/1891 [==============================] - 54s 28ms/step - loss: 84264.2634 - accuracy: 0.5291\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1121.9299 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 69140.3638 - accuracy: 0.5292\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1178.2533 - accuracy: 0.4945\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 52699.9974 - accuracy: 0.5136\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 11537.6172 - accuracy: 0.5842\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 106719.1547 - accuracy: 0.5276\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 13316.0674 - accuracy: 0.6373\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 58570.1108 - accuracy: 0.5201\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 9476.0830 - accuracy: 0.5696\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 53824.8254 - accuracy: 0.5209\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 2351.5037 - accuracy: 0.5613\n",
      "1891/1891 [==============================] - 53s 28ms/step - loss: 66227.0174 - accuracy: 0.5141\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 954.7896 - accuracy: 0.5990\n",
      "1891/1891 [==============================] - 53s 27ms/step - loss: 77236.0954 - accuracy: 0.5250\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 563.9970 - accuracy: 0.6726\n",
      "1891/1891 [==============================] - 49s 25ms/step - loss: 95349.1250 - accuracy: 0.5138\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 1758.6152 - accuracy: 0.6551\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 81263.0876 - accuracy: 0.5222\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 2251.5535 - accuracy: 0.5899\n",
      "1891/1891 [==============================] - 52s 27ms/step - loss: 65595.5275 - accuracy: 0.5091\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1612.8801 - accuracy: 0.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 52s 27ms/step - loss: 79677.2351 - accuracy: 0.5238\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 5446.6768 - accuracy: 0.5571\n",
      "1891/1891 [==============================] - 51s 27ms/step - loss: 56558.9544 - accuracy: 0.5229\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 4436.4668 - accuracy: 0.6180\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 66704.8591 - accuracy: 0.5211\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 44.9029 - accuracy: 0.6674\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 51147.9522 - accuracy: 0.4965\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 875.4719 - accuracy: 0.6788\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 62664.2036 - accuracy: 0.4923\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 2690.7317 - accuracy: 0.6434\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 71299.7804 - accuracy: 0.5160\n",
      "237/237 [==============================] - 2s 5ms/step - loss: 1360.8014 - accuracy: 0.5673\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 73045.3681 - accuracy: 0.5232\n",
      "237/237 [==============================] - 2s 5ms/step - loss: 1794.2122 - accuracy: 0.6282\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 95158.7832 - accuracy: 0.5240\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 3338.0681 - accuracy: 0.5476\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 44726.2050 - accuracy: 0.5214\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 992.5731 - accuracy: 0.6157\n",
      "946/946 [==============================] - 28s 28ms/step - loss: 95530.4557 - accuracy: 0.5279\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 2120.5813 - accuracy: 0.4505\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 48131.5384 - accuracy: 0.5294\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 130.6887 - accuracy: 0.6455\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 81737.3532 - accuracy: 0.5148\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 12247.0635 - accuracy: 0.5842\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 70171.2775 - accuracy: 0.5203\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 698.3573 - accuracy: 0.6335\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 101685.5789 - accuracy: 0.5136\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 3326.9670 - accuracy: 0.5637\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 47396.2408 - accuracy: 0.5269\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 2496.1306 - accuracy: 0.6447\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 66026.8249 - accuracy: 0.5211\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 17364.9863 - accuracy: 0.5571\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 45959.0461 - accuracy: 0.52310s - loss: 45979.1043 - accuracy: 0.52\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 1489.4003 - accuracy: 0.6624\n",
      "946/946 [==============================] - 28s 28ms/step - loss: 74721.9873 - accuracy: 0.5085\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 2300.6877 - accuracy: 0.5476\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 48584.1826 - accuracy: 0.5233\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 7525.6304 - accuracy: 0.5603\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 84984.4315 - accuracy: 0.5172\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 5584.7124 - accuracy: 0.5647\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 75185.2561 - accuracy: 0.5298\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 7993.4087 - accuracy: 0.5571\n",
      "946/946 [==============================] - 29s 30ms/step - loss: 63194.2069 - accuracy: 0.5166\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2244.8933 - accuracy: 0.5529\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 50713.2874 - accuracy: 0.5279\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 3485.7761 - accuracy: 0.6081\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 77582.9386 - accuracy: 0.5251\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 183.0628 - accuracy: 0.6492\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 42694.6980 - accuracy: 0.5341\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 344.4647 - accuracy: 0.6041\n",
      "946/946 [==============================] - 27s 28ms/step - loss: 62342.5723 - accuracy: 0.5127\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 18569.6113 - accuracy: 0.5571\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 67843.1871 - accuracy: 0.5210\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 780.7348 - accuracy: 0.6743\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 55263.8489 - accuracy: 0.5013\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 1467.8909 - accuracy: 0.6069\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 60970.4106 - accuracy: 0.5182\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2957.4265 - accuracy: 0.5696\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 108805.2230 - accuracy: 0.5220\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 30261.9551 - accuracy: 0.5647\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 60784.3094 - accuracy: 0.5104\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 4666.7778 - accuracy: 0.6332\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 62392.3093 - accuracy: 0.5299\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 3366.4316 - accuracy: 0.5842\n",
      "946/946 [==============================] - 29s 30ms/step - loss: 65367.5188 - accuracy: 0.5204\n",
      "237/237 [==============================] - 2s 5ms/step - loss: 1702.6490 - accuracy: 0.6276\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 33174.0623 - accuracy: 0.4988\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 8378.0684 - accuracy: 0.5696\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 51996.1052 - accuracy: 0.5152\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 3018.8701 - accuracy: 0.6781\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 81532.0659 - accuracy: 0.5160\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 6949.9214 - accuracy: 0.5571\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 75871.6989 - accuracy: 0.5174\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 6464.8491 - accuracy: 0.5770\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 55080.9076 - accuracy: 0.5294\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2738.6929 - accuracy: 0.5091\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 51248.3856 - accuracy: 0.5157\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 10197.4375 - accuracy: 0.5696\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 64301.5045 - accuracy: 0.5249\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 3638.0388 - accuracy: 0.5415\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 59119.1009 - accuracy: 0.5094\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 2861.9438 - accuracy: 0.6125\n",
      "946/946 [==============================] - 29s 30ms/step - loss: 55179.3528 - accuracy: 0.5323\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 454.3894 - accuracy: 0.5787\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 64166.1544 - accuracy: 0.5299\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 461.3169 - accuracy: 0.6665\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 74956.0083 - accuracy: 0.4994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 2s 6ms/step - loss: 2365.5391 - accuracy: 0.5696\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 59644.0341 - accuracy: 0.5201\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 714.3080 - accuracy: 0.6459\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 48944.5782 - accuracy: 0.5106\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 2562.2288 - accuracy: 0.6146\n",
      "946/946 [==============================] - 29s 30ms/step - loss: 108100.1137 - accuracy: 0.5157\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 880.4432 - accuracy: 0.6637\n",
      "946/946 [==============================] - 30s 30ms/step - loss: 56320.3406 - accuracy: 0.5128\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 5886.4053 - accuracy: 0.4524\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 74380.7955 - accuracy: 0.5193\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 1416.1007 - accuracy: 0.6052\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 77389.3911 - accuracy: 0.5152\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2728.9250 - accuracy: 0.5647\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 53990.3966 - accuracy: 0.5172\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 29006.5879 - accuracy: 0.5571\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 61474.0836 - accuracy: 0.5260\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 71.9351 - accuracy: 0.6701\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 101852.7010 - accuracy: 0.5147\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 5131.0459 - accuracy: 0.6276\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 57393.7991 - accuracy: 0.5172\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2298.3770 - accuracy: 0.5887\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 50546.4723 - accuracy: 0.5201\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 4181.7026 - accuracy: 0.5647\n",
      "946/946 [==============================] - 29s 30ms/step - loss: 47221.3755 - accuracy: 0.5035\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2156.8499 - accuracy: 0.5673\n",
      "946/946 [==============================] - 28s 28ms/step - loss: 50580.8799 - accuracy: 0.4974\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2454.7095 - accuracy: 0.6506\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 71624.7784 - accuracy: 0.5180\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 5716.5503 - accuracy: 0.5476\n",
      "946/946 [==============================] - 28s 29ms/step - loss: 124380.9225 - accuracy: 0.5294\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 2586.7061 - accuracy: 0.6339\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 61993.1478 - accuracy: 0.5020\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 5224.9937 - accuracy: 0.5647\n",
      "946/946 [==============================] - 32s 32ms/step - loss: 58201.7030 - accuracy: 0.5101\n",
      "237/237 [==============================] - 3s 10ms/step - loss: 17120.8457 - accuracy: 0.5571\n",
      "946/946 [==============================] - 33s 34ms/step - loss: 63159.7696 - accuracy: 0.5176\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 286.0816 - accuracy: 0.6701\n",
      "946/946 [==============================] - 30s 30ms/step - loss: 87583.8672 - accuracy: 0.5074\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 849.8485 - accuracy: 0.6568\n",
      "946/946 [==============================] - 31s 32ms/step - loss: 42866.9483 - accuracy: 0.5046\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 6400.0869 - accuracy: 0.5975\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 71774.6444 - accuracy: 0.5132\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 902.5602 - accuracy: 0.6734\n",
      "946/946 [==============================] - 29s 30ms/step - loss: 50007.7061 - accuracy: 0.5022\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 1780.5675 - accuracy: 0.5571\n",
      "946/946 [==============================] - 32s 32ms/step - loss: 52390.1124 - accuracy: 0.5145\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 24866.2656 - accuracy: 0.5842\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 56814.5160 - accuracy: 0.5076\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 2335.1943 - accuracy: 0.6102\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 76677.8987 - accuracy: 0.5189\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 873.6060 - accuracy: 0.5087\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 95474.9541 - accuracy: 0.5142\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 1295.9481 - accuracy: 0.5647\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 58584.5896 - accuracy: 0.5083\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 1134.0668 - accuracy: 0.6434\n",
      "946/946 [==============================] - 29s 30ms/step - loss: 65973.0373 - accuracy: 0.52800s - loss: 66445.0339 - \n",
      "237/237 [==============================] - 2s 8ms/step - loss: 681.4353 - accuracy: 0.5922\n",
      "946/946 [==============================] - 31s 32ms/step - loss: 57463.1460 - accuracy: 0.5181\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 911.1769 - accuracy: 0.5476\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 71041.1131 - accuracy: 0.5125\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 1401.2058 - accuracy: 0.5696\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 62048.9547 - accuracy: 0.5184\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 1567.9663 - accuracy: 0.6768\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 87639.6063 - accuracy: 0.5283\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 1475.7789 - accuracy: 0.6646\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 54511.5305 - accuracy: 0.4928\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 1254.9933 - accuracy: 0.6049\n",
      "946/946 [==============================] - 29s 29ms/step - loss: 81270.6359 - accuracy: 0.5044\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 4736.7700 - accuracy: 0.5476\n",
      "946/946 [==============================] - 30s 30ms/step - loss: 62370.5572 - accuracy: 0.5053\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 367.5297 - accuracy: 0.6644\n",
      "946/946 [==============================] - 33s 33ms/step - loss: 79958.4158 - accuracy: 0.5262\n",
      "237/237 [==============================] - 2s 6ms/step - loss: 3403.3474 - accuracy: 0.5410\n",
      "946/946 [==============================] - 32s 33ms/step - loss: 51266.3972 - accuracy: 0.5136\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 5301.0288 - accuracy: 0.4471\n",
      "946/946 [==============================] - 32s 33ms/step - loss: 65728.8135 - accuracy: 0.5161\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 1032.6301 - accuracy: 0.6586\n",
      "946/946 [==============================] - 32s 33ms/step - loss: 70235.0443 - accuracy: 0.5126\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 3665.6497 - accuracy: 0.5002\n",
      "946/946 [==============================] - 32s 32ms/step - loss: 54243.3485 - accuracy: 0.5134\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 1663.1853 - accuracy: 0.6348\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 58864.5652 - accuracy: 0.5165\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 833.6656 - accuracy: 0.5647\n",
      "946/946 [==============================] - 30s 31ms/step - loss: 58408.2508 - accuracy: 0.5120\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 8359.0889 - accuracy: 0.5571\n",
      "946/946 [==============================] - 35s 36ms/step - loss: 49064.1228 - accuracy: 0.5189\n",
      "237/237 [==============================] - 2s 9ms/step - loss: 110.3611 - accuracy: 0.6578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 32s 32ms/step - loss: 107593.0804 - accuracy: 0.5052\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 682.0231 - accuracy: 0.5624\n",
      "946/946 [==============================] - 33s 33ms/step - loss: 55721.0598 - accuracy: 0.5137\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 2052.7578 - accuracy: 0.6458\n",
      "946/946 [==============================] - 31s 32ms/step - loss: 83541.4764 - accuracy: 0.5251\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 4024.4214 - accuracy: 0.5660\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 55013.8764 - accuracy: 0.5194\n",
      "237/237 [==============================] - 2s 8ms/step - loss: 182.7583 - accuracy: 0.6400\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 49854.2947 - accuracy: 0.5192\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 3736.6260 - accuracy: 0.5685\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 60277.2374 - accuracy: 0.5089\n",
      "237/237 [==============================] - 2s 7ms/step - loss: 3393.5901 - accuracy: 0.5476\n",
      "946/946 [==============================] - 31s 31ms/step - loss: 69299.1676 - accuracy: 0.5180\n",
      "237/237 [==============================] - ETA: 0s - loss: 3334.3857 - accuracy: 0.570 - 2s 8ms/step - loss: 3333.9827 - accuracy: 0.5696\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 66282.0372 - accuracy: 0.5290\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 4187.5947 - accuracy: 0.5647\n",
      "473/473 [==============================] - 20s 39ms/step - loss: 47326.7348 - accuracy: 0.5077\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 9248.2822 - accuracy: 0.5571\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 52799.0783 - accuracy: 0.5176\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2363.4766 - accuracy: 0.5833\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 70686.6020 - accuracy: 0.5017\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 5373.5498 - accuracy: 0.5476\n",
      "473/473 [==============================] - 20s 39ms/step - loss: 56770.4961 - accuracy: 0.5193\n",
      "119/119 [==============================] - 2s 10ms/step - loss: 5429.9062 - accuracy: 0.5497\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 45247.1823 - accuracy: 0.5108\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2698.6921 - accuracy: 0.6015\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 73159.9830 - accuracy: 0.5087\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 29514.3828 - accuracy: 0.5571\n",
      "473/473 [==============================] - 17s 33ms/step - loss: 65491.3759 - accuracy: 0.5185\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2401.3372 - accuracy: 0.6311\n",
      "473/473 [==============================] - 17s 33ms/step - loss: 53677.8888 - accuracy: 0.5187\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 1796.8246 - accuracy: 0.6678\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 49709.8738 - accuracy: 0.5099\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 7549.5337 - accuracy: 0.5696\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 59069.9828 - accuracy: 0.5147\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2838.8979 - accuracy: 0.5647\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 45766.5632 - accuracy: 0.5025\n",
      "119/119 [==============================] - 2s 8ms/step - loss: 2214.3972 - accuracy: 0.5990\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 51634.9983 - accuracy: 0.5138\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 13808.3779 - accuracy: 0.5842\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 82106.0719 - accuracy: 0.5157\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2286.3232 - accuracy: 0.6648\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 69326.0587 - accuracy: 0.5155\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 4164.5000 - accuracy: 0.6060\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 53597.0731 - accuracy: 0.5261\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 2655.8518 - accuracy: 0.5740\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 49564.7204 - accuracy: 0.5124\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 1912.7480 - accuracy: 0.5571\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 122111.9083 - accuracy: 0.5085\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 4810.4014 - accuracy: 0.6015\n",
      "473/473 [==============================] - 17s 33ms/step - loss: 47911.3114 - accuracy: 0.5182\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 13419.8633 - accuracy: 0.5476\n",
      "473/473 [==============================] - 16s 33ms/step - loss: 42295.0246 - accuracy: 0.4973\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 971.5325 - accuracy: 0.5696\n",
      "473/473 [==============================] - 16s 32ms/step - loss: 59595.4596 - accuracy: 0.5058\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 16661.9531 - accuracy: 0.5647\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 85993.1273 - accuracy: 0.4968\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 3374.6853 - accuracy: 0.6172\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 43584.1473 - accuracy: 0.5019\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 1632.9655 - accuracy: 0.5833\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 128442.6876 - accuracy: 0.4999\n",
      "119/119 [==============================] - 2s 10ms/step - loss: 9830.7900 - accuracy: 0.5476\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 50407.3539 - accuracy: 0.5112\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 1533.0005 - accuracy: 0.5696\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 67641.9249 - accuracy: 0.5057\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 1340.6873 - accuracy: 0.5647\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 61363.9242 - accuracy: 0.4955\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 2864.9517 - accuracy: 0.6303\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 42894.3409 - accuracy: 0.5073\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 1201.1923 - accuracy: 0.5804\n",
      "473/473 [==============================] - 19s 37ms/step - loss: 59169.2752 - accuracy: 0.5090\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 9645.3994 - accuracy: 0.5476\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 59109.6262 - accuracy: 0.5072\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 1009.5636 - accuracy: 0.6441\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 70353.1163 - accuracy: 0.5018\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 4529.4849 - accuracy: 0.5228\n",
      "473/473 [==============================] - 17s 33ms/step - loss: 71559.8816 - accuracy: 0.5138\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 5462.6260 - accuracy: 0.6798\n",
      "473/473 [==============================] - 16s 32ms/step - loss: 55954.2043 - accuracy: 0.5151\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 3020.9124 - accuracy: 0.5842\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 58508.5593 - accuracy: 0.5181\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 4275.2104 - accuracy: 0.6107\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 75444.3041 - accuracy: 0.5120\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 1403.7250 - accuracy: 0.5734\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 68336.1743 - accuracy: 0.4980\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 6645.9668 - accuracy: 0.6231\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 45969.5567 - accuracy: 0.5033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 8ms/step - loss: 150.8442 - accuracy: 0.6172\n",
      "473/473 [==============================] - 16s 32ms/step - loss: 130897.2083 - accuracy: 0.4975\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2053.8899 - accuracy: 0.6751\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 69505.7818 - accuracy: 0.5050\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 405.9374 - accuracy: 0.6686\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 46001.5149 - accuracy: 0.5160\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7504.2261 - accuracy: 0.5768\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 66732.0266 - accuracy: 0.5070\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 2304.1909 - accuracy: 0.5656\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 52114.7654 - accuracy: 0.5008\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 4844.6724 - accuracy: 0.5905\n",
      "473/473 [==============================] - 19s 37ms/step - loss: 61120.4570 - accuracy: 0.5193\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2601.6089 - accuracy: 0.6129\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 53090.6363 - accuracy: 0.5158\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 2354.1226 - accuracy: 0.5916\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 54125.4151 - accuracy: 0.5286\n",
      "119/119 [==============================] - 2s 9ms/step - loss: 203.8879 - accuracy: 0.5696\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 62173.4072 - accuracy: 0.5200\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 1406.2101 - accuracy: 0.6519\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 53156.1169 - accuracy: 0.5096\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 3320.0435 - accuracy: 0.5808\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 87475.1818 - accuracy: 0.5023\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 12519.2119 - accuracy: 0.5842\n",
      "473/473 [==============================] - 17s 33ms/step - loss: 68651.9560 - accuracy: 0.5158\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 336.5580 - accuracy: 0.5946\n",
      "473/473 [==============================] - 17s 35ms/step - loss: 55067.2839 - accuracy: 0.5020\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 481.6997 - accuracy: 0.5696\n",
      "473/473 [==============================] - 17s 33ms/step - loss: 59344.9871 - accuracy: 0.5204\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 4106.4736 - accuracy: 0.5863\n",
      "473/473 [==============================] - 18s 34ms/step - loss: 59762.0309 - accuracy: 0.5181\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 4390.0996 - accuracy: 0.5571\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 58535.2242 - accuracy: 0.5136\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 3218.5347 - accuracy: 0.6121\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 59392.2735 - accuracy: 0.4931\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 3987.1841 - accuracy: 0.6327\n",
      "473/473 [==============================] - 18s 37ms/step - loss: 69752.6274 - accuracy: 0.5070\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2702.8423 - accuracy: 0.6369\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 55464.7701 - accuracy: 0.5288\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 1479.4431 - accuracy: 0.6349\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 89918.4856 - accuracy: 0.5128\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 13826.4248 - accuracy: 0.5571\n",
      "473/473 [==============================] - 19s 38ms/step - loss: 42846.3441 - accuracy: 0.5065\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 7264.2485 - accuracy: 0.5842\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 70997.5847 - accuracy: 0.5091\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7792.3599 - accuracy: 0.5442\n",
      "473/473 [==============================] - 19s 37ms/step - loss: 56635.8583 - accuracy: 0.5241\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 3829.1528 - accuracy: 0.5722\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 57378.1547 - accuracy: 0.5071\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 353.4655 - accuracy: 0.5076\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 75693.7358 - accuracy: 0.5157\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 1009.4488 - accuracy: 0.5863\n",
      "473/473 [==============================] - 17s 33ms/step - loss: 53250.4721 - accuracy: 0.5305\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 5218.5132 - accuracy: 0.5842\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 67364.8465 - accuracy: 0.5171\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 11051.8105 - accuracy: 0.4524\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 65651.5183 - accuracy: 0.5073\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 624.8307 - accuracy: 0.5696\n",
      "473/473 [==============================] - 19s 38ms/step - loss: 69775.2248 - accuracy: 0.5149\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 7744.4780 - accuracy: 0.4353\n",
      "473/473 [==============================] - 18s 34ms/step - loss: 56453.0078 - accuracy: 0.51400s - loss: 56665.4935 - accuracy: \n",
      "119/119 [==============================] - 1s 9ms/step - loss: 6352.3989 - accuracy: 0.5816\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 47335.5044 - accuracy: 0.5079\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 386.3382 - accuracy: 0.5842\n",
      "473/473 [==============================] - 19s 37ms/step - loss: 75216.6099 - accuracy: 0.5204\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 6783.0737 - accuracy: 0.5476\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 44537.6064 - accuracy: 0.5049\n",
      "119/119 [==============================] - 2s 10ms/step - loss: 666.0878 - accuracy: 0.5662\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 89723.5508 - accuracy: 0.5165\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 10387.9824 - accuracy: 0.5647\n",
      "473/473 [==============================] - 18s 34ms/step - loss: 66205.3959 - accuracy: 0.5161\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 3445.4324 - accuracy: 0.6151\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 67039.8403 - accuracy: 0.5117\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 12232.8965 - accuracy: 0.5842\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 50898.2804 - accuracy: 0.5072\n",
      "119/119 [==============================] - 2s 10ms/step - loss: 2458.3279 - accuracy: 0.4871\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 54024.1587 - accuracy: 0.5179\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 16414.5938 - accuracy: 0.6052\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 51637.6739 - accuracy: 0.5002\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2038.4503 - accuracy: 0.6400\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 69210.7621 - accuracy: 0.5138\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 5844.0654 - accuracy: 0.5799\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 58771.2300 - accuracy: 0.4998\n",
      "119/119 [==============================] - 2s 9ms/step - loss: 1332.1356 - accuracy: 0.5706\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 56171.2047 - accuracy: 0.5127\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 2384.6201 - accuracy: 0.6267\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 64584.8391 - accuracy: 0.5207\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 4791.2969 - accuracy: 0.5527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/473 [==============================] - 18s 36ms/step - loss: 61940.2934 - accuracy: 0.5112\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 13306.0039 - accuracy: 0.5144\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 39314.3652 - accuracy: 0.5211\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 2139.4087 - accuracy: 0.5478\n",
      "473/473 [==============================] - 17s 34ms/step - loss: 123281.6295 - accuracy: 0.5108\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 511.6502 - accuracy: 0.5842\n",
      "473/473 [==============================] - 19s 37ms/step - loss: 66935.0531 - accuracy: 0.5085\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 12285.0859 - accuracy: 0.5476\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 62333.5122 - accuracy: 0.5044\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 808.1057 - accuracy: 0.5281\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 49763.9767 - accuracy: 0.5163\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 960.6915 - accuracy: 0.6760\n",
      "473/473 [==============================] - 18s 37ms/step - loss: 46545.5354 - accuracy: 0.5209\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 3535.2910 - accuracy: 0.5571\n",
      "473/473 [==============================] - 18s 35ms/step - loss: 45546.9469 - accuracy: 0.4986\n",
      "119/119 [==============================] - 1s 8ms/step - loss: 5819.3540 - accuracy: 0.5745\n",
      "473/473 [==============================] - 19s 38ms/step - loss: 54523.7878 - accuracy: 0.4966\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 4746.4194 - accuracy: 0.5844\n",
      "473/473 [==============================] - 18s 36ms/step - loss: 70909.1780 - accuracy: 0.5169\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 3776.2861 - accuracy: 0.6348\n",
      "2364/2364 [==============================] - 71s 29ms/step - loss: 58211.1732 - accuracy: 0.5160\n",
      "{'batch_size': 5, 'init': 'normal', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "1013/1013 [==============================] - 6s 6ms/step - loss: 1311.8948 - accuracy: 0.5828\n",
      "dnn: 0.5828232765197754\n"
     ]
    }
   ],
   "source": [
    "DNN_mean = dnn(x_train_mean_encoding,y_train_mean_encoding,x_validation_mean_encoding,y_validation_mean_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/violeta/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/home/violeta/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/violeta/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.28%, Logloss: nan\n",
      "1891/1891 [==============================] - 54s 28ms/step - loss: 69229.8118 - accuracy: 0.5095\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 14696.2373 - accuracy: 0.5647\n",
      "1891/1891 [==============================] - 55s 29ms/step - loss: 84806.6368 - accuracy: 0.5309\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 1349.7698 - accuracy: 0.5918\n",
      "1891/1891 [==============================] - 55s 28ms/step - loss: 54363.6188 - accuracy: 0.5183\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 434.3853 - accuracy: 0.5854\n",
      "1891/1891 [==============================] - 56s 29ms/step - loss: 78931.8251 - accuracy: 0.5144\n",
      "473/473 [==============================] - 3s 7ms/step - loss: 11450.8760 - accuracy: 0.6492\n",
      "1891/1891 [==============================] - 55s 29ms/step - loss: 66605.5187 - accuracy: 0.5218\n",
      "473/473 [==============================] - 3s 6ms/step - loss: 3445.0415 - accuracy: 0.5696\n",
      "0.5921504855155945\n"
     ]
    }
   ],
   "source": [
    "test_model(DNN_mean,x_validation_mean_encoding,y_validation_mean_encoding)\n",
    "cross_val(DNN_mean, x_train_mean_encoding, y_train_mean_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERCEPTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x_train, y_train, x_validation, y_validation):\n",
    "    perceptron = Perceptron(tol=1e-3, random_state=0)\n",
    "    params_perc = {'alpha': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3]}\n",
    "    per_gs = model_selection.GridSearchCV(perceptron, params_perc, cv=5)\n",
    "    per_gs.fit(x_train, y_train)\n",
    "    per_best = per_gs.best_estimator_\n",
    "    print(per_gs.best_params_)\n",
    "    print('perceptron: {}'.format(per_best.score(x_validation, y_validation)))\n",
    "    return per_gs\n",
    "\n",
    "def multi_perceptron(x_train, y_train, x_validation, y_validation):\n",
    "    mult_perceptron = MLPClassifier(tol=1e-3, random_state=0)\n",
    "    params_mult_perc =  {'hidden_layer_sizes': [(10,30,10),(20,)],'activation': ['tanh', 'relu'],'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "    mul_per_gs = model_selection.GridSearchCV(mult_perceptron, params_mult_perc, cv=5)\n",
    "    mul_per_gs.fit(x_train, y_train)\n",
    "    mul_per_best = mul_per_gs.best_estimator_\n",
    "    print(mul_per_gs.best_params_)\n",
    "    print('multi perceptron: {}'.format(mul_per_best.score(x_validation, y_validation)))\n",
    "    return mul_per_best\n",
    "\n",
    "def multi_perceptron_2(x_train, y_train, x_validation, y_validation):\n",
    "    mult_perceptron_2 = MLPRegressor()\n",
    "    params_mult_perc_2 = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (20,)],'activation': ['relu','tanh','logistic'],\n",
    "          'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive'],\n",
    "          'solver': ['sgd', 'adam']}\n",
    "    mul_per_gs_2 = model_selection.GridSearchCV(mult_perceptron_2, params_mult_perc_2, cv=5)\n",
    "    mul_per_gs_2.fit(x_train, y_train)\n",
    "    mul_per_best_2 = mul_per_gs_2.best_estimator_\n",
    "    print(mul_per_gs_2.best_params_)\n",
    "    print('multi perceptron 2: {}'.format(mul_per_best_2.score(x_validation, y_validation)))\n",
    "    return mul_per_gs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "multi perceptron: 0.5646594274432379\n",
      "Accuracy: 56.47%, Logloss: 0.67\n",
      "0.6711795568024529\n"
     ]
    }
   ],
   "source": [
    "PERC_mean = multi_perceptron(x_train_mean_encoding,y_train_mean_encoding,x_validation_mean_encoding,y_validation_mean_encoding)\n",
    "test_model(PERC_mean,x_validation_mean_encoding,y_validation_mean_encoding)\n",
    "cross_val(PERC_mean, x_train_mean_encoding, y_train_mean_encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
