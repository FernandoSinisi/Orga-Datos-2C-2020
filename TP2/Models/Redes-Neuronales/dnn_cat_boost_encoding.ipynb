{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import CatBoostEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Input\n",
    "from keras.layers import  Dropout, Dense, Activation\n",
    "from tensorflow.keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../Feature_Engineering/data/other-cleaned_train.csv')\n",
    "test = pd.read_csv('../../Feature_Engineering/data/other-cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "test.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_columns = train.drop(columns = [\"Opportunity_ID\",\"ID\", \"Pricing, Delivery_Terms_Quote_Appr\",\\\n",
    "                                    \"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\\\n",
    "                                    \"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount\",\\\n",
    "                                    \"Total_Taxable_Amount\",\"diferencia_en_dias\",\"Last_Modified_DOY\",\"Last_Modified_Year\",\\\n",
    "                                    \"Opportunity_Created_DOY\",\"Opportunity_Created_Year\",\"Quote_Expiry_DOY\",\\\n",
    "                                     \"Quote_Expiry_Year\",\"Planned_Delivery_Start_DOY\",\"Planned_Delivery_Start_Year\",\\\n",
    "                                    \"Planned_Delivery_End_DOY\",\"Planned_Delivery_End_Year\",\\\n",
    "                                    \"Target\"]).columns\n",
    "for column in categ_columns:\n",
    "    encoder = CatBoostEncoder()\n",
    "    encoder.fit(train[column], train['Target'])\n",
    "    feature_encoded = encoder.transform(train[column])\n",
    "    X_train = X_train.join(feature_encoded.add_suffix('_cat_boost'))\n",
    "    X_train.drop(columns=[column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_columns = test.drop(columns = [\"Opportunity_ID\",\"ID\", \"Pricing, Delivery_Terms_Quote_Appr\",\\\n",
    "                                    \"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\\\n",
    "                                    \"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount\",\\\n",
    "                                    \"Total_Taxable_Amount\",\"diferencia_en_dias\",\"Last_Modified_DOY\",\"Last_Modified_Year\",\\\n",
    "                                    \"Opportunity_Created_DOY\",\"Opportunity_Created_Year\",\"Quote_Expiry_DOY\",\\\n",
    "                                     \"Quote_Expiry_Year\",\"Planned_Delivery_Start_DOY\",\"Planned_Delivery_Start_Year\",\\\n",
    "                                    \"Planned_Delivery_End_DOY\",\"Planned_Delivery_End_Year\"]).columns\n",
    "for column in categ_columns:\n",
    "    encoder = CatBoostEncoder()\n",
    "    encoder.fit(train[column], train['Target'])\n",
    "    feature_encoded = encoder.transform(test[column])\n",
    "    X_test = X_test.join(feature_encoded.add_suffix('_cat_boost'))\n",
    "    X_test.drop(columns=[column], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"Total_Amount\"] = pd.to_numeric(X_train[\"Total_Amount\"],errors='coerce').fillna(X_train[\"Total_Amount\"].mean())\n",
    "X_train[\"Opportunity_Created_Year\"] = pd.to_numeric(X_train[\"Opportunity_Created_Year\"],errors='coerce').fillna(0)\n",
    "X_train[\"Quote_Expiry_DOY\"] = pd.to_numeric(X_train[\"Quote_Expiry_DOY\"],errors='coerce').fillna(0)\n",
    "X_train[\"Quote_Expiry_Year\"] = pd.to_numeric(X_train[\"Quote_Expiry_Year\"],errors='coerce').fillna(0)\n",
    "X_train[\"Planned_Delivery_End_DOY\"] = pd.to_numeric(X_train[\"Planned_Delivery_End_DOY\"],errors='coerce').fillna(0)\n",
    "X_train[\"Planned_Delivery_End_Year\"] = pd.to_numeric(X_train[\"Planned_Delivery_End_Year\"],errors='coerce').fillna(0)\n",
    "\n",
    "X_train = X_train.drop(columns = 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"Total_Amount\"] = pd.to_numeric(X_test[\"Total_Amount\"],errors='coerce').fillna(test[\"Total_Amount\"].mean())\n",
    "X_test[\"Opportunity_Created_Year\"] = pd.to_numeric(X_test[\"Opportunity_Created_Year\"],errors='coerce').fillna(0)\n",
    "X_test[\"Quote_Expiry_DOY\"] = pd.to_numeric(X_test[\"Quote_Expiry_DOY\"],errors='coerce').fillna(0)\n",
    "X_test[\"Quote_Expiry_Year\"] = pd.to_numeric(X_test[\"Quote_Expiry_Year\"],errors='coerce').fillna(0)\n",
    "X_test[\"Planned_Delivery_End_DOY\"] = pd.to_numeric(X_test[\"Planned_Delivery_End_DOY\"],errors='coerce').fillna(0)\n",
    "X_test[\"Planned_Delivery_End_Year\"] = pd.to_numeric(X_test[\"Planned_Delivery_End_Year\"],errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, x_train, y_train):\n",
    "    score_cross_val = model_selection.cross_val_score(model, x_train, y_train, cv=5)\n",
    "    print(score_cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_model(optimizer='rmsprop',init='glorot_uniform'):\n",
    "    node = 512\n",
    "    nClasses = 2\n",
    "    dropout=0.5\n",
    "    nFeatures = 55\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(node,input_dim=nFeatures,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,4):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(x_train, y_train, x_validation, y_validation):\n",
    "    keras_model = KerasClassifier(build_fn=DNN_model)\n",
    "    optimizers = ['rmsprop', 'adam']\n",
    "    init = ['glorot_uniform', 'normal', 'uniform']\n",
    "    epochs = [50, 100, 150]\n",
    "    batches = batches = [5, 10, 20]\n",
    "    param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "    dnn_gs = GridSearchCV(keras_model, param_grid=param_grid)\n",
    "    dnn_gs.fit(x_train, y_train)\n",
    "    dnn_best = dnn_gs.best_estimator_\n",
    "    print(dnn_gs.best_params_)\n",
    "    print('dnn: {}'.format(dnn_best.score(x_validation, y_validation)))\n",
    "    return dnn_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    predictions = model.predict_proba(x_test)[:,1]\n",
    "    logloss = log_loss(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions.round())\n",
    "    print(\"Accuracy: %.2f%%, Logloss: %.2f\" % (accuracy*100.0, logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_features(model,train):\n",
    "    importance = model.feature_importances_\n",
    "    result = pd.DataFrame([train.columns,importance]).transpose()\n",
    "    result.columns = [\"Feature\",\"Importance\"]\n",
    "    return result.sort_values(by='Importance', ascending=False).head(15)[\"Feature\"].to_list()\n",
    "    \n",
    "    \n",
    "def plot_features(model,train):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(350, 350)\n",
    "    selection = SelectFromModel(model, threshold=0.040, prefit=True)\n",
    "    selected_dataset = selection.transform(train)\n",
    "    model.plot_importance(booster=model)\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,20)\n",
    "    plt.xlabel(\"\\nFeature importance\", fontsize=40)\n",
    "    plt.ylabel(\"Features\", fontsize=35)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Target\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X_train, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 5s 2ms/step - loss: 51377.8341 - accuracy: 0.5313\n",
      "473/473 [==============================] - 0s 692us/step - loss: 5584.4438 - accuracy: 0.5584\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 125308.2589 - accuracy: 0.5404\n",
      "473/473 [==============================] - 1s 890us/step - loss: 6311.5601 - accuracy: 0.5537\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 60946.1050 - accuracy: 0.5009\n",
      "473/473 [==============================] - 1s 829us/step - loss: 2720.8994 - accuracy: 0.6591\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 51628.8515 - accuracy: 0.5207\n",
      "473/473 [==============================] - 0s 778us/step - loss: 722.5490 - accuracy: 0.6737\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 67197.6176 - accuracy: 0.5269\n",
      "473/473 [==============================] - 0s 735us/step - loss: 772.2629 - accuracy: 0.6665\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 52347.6949 - accuracy: 0.5202\n",
      "473/473 [==============================] - 1s 897us/step - loss: 2960.4280 - accuracy: 0.5571\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 67368.2270 - accuracy: 0.5261\n",
      "473/473 [==============================] - 1s 934us/step - loss: 889.9673 - accuracy: 0.5795\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 75395.8173 - accuracy: 0.5194\n",
      "473/473 [==============================] - 1s 935us/step - loss: 5853.5713 - accuracy: 0.5588\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 59927.2777 - accuracy: 0.5289\n",
      "473/473 [==============================] - 1s 812us/step - loss: 2126.9731 - accuracy: 0.4545\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 60556.4314 - accuracy: 0.5248\n",
      "473/473 [==============================] - 1s 886us/step - loss: 2639.9731 - accuracy: 0.6297\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 36514.4758 - accuracy: 0.5157\n",
      "473/473 [==============================] - 0s 736us/step - loss: 4978.6831 - accuracy: 0.5698\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 54647.3802 - accuracy: 0.5153\n",
      "473/473 [==============================] - 0s 764us/step - loss: 5411.9429 - accuracy: 0.5745\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 49185.0566 - accuracy: 0.5172\n",
      "473/473 [==============================] - 1s 845us/step - loss: 500.4053 - accuracy: 0.6349\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 88995.8522 - accuracy: 0.5245\n",
      "473/473 [==============================] - 1s 858us/step - loss: 1402.5083 - accuracy: 0.5645\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 86584.7380 - accuracy: 0.5239\n",
      "473/473 [==============================] - 1s 890us/step - loss: 7105.7192 - accuracy: 0.5671\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 45036.0691 - accuracy: 0.5171\n",
      "473/473 [==============================] - 1s 887us/step - loss: 2874.5210 - accuracy: 0.5842\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 63649.2206 - accuracy: 0.5208\n",
      "473/473 [==============================] - 1s 897us/step - loss: 1286.7777 - accuracy: 0.5745\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 60658.5509 - accuracy: 0.5124\n",
      "473/473 [==============================] - 1s 899us/step - loss: 3866.4341 - accuracy: 0.6662\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 74605.5502 - accuracy: 0.5176\n",
      "473/473 [==============================] - 1s 854us/step - loss: 2439.1309 - accuracy: 0.6720\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 59152.3008 - accuracy: 0.5106\n",
      "473/473 [==============================] - 1s 835us/step - loss: 18.4352 - accuracy: 0.5645\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 55302.8714 - accuracy: 0.5164\n",
      "473/473 [==============================] - 1s 1000us/step - loss: 4872.4224 - accuracy: 0.6129\n",
      "1891/1891 [==============================] - 7s 3ms/step - loss: 70627.3464 - accuracy: 0.5207\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 1003.9973 - accuracy: 0.6129\n",
      "1891/1891 [==============================] - 7s 3ms/step - loss: 66555.6703 - accuracy: 0.5167\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 2686.1099 - accuracy: 0.6193\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 48009.9278 - accuracy: 0.5206\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 420.3124 - accuracy: 0.6204\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 53225.5073 - accuracy: 0.5159\n",
      "473/473 [==============================] - 1s 965us/step - loss: 914.2632 - accuracy: 0.6238\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 75017.4874 - accuracy: 0.5224\n",
      "473/473 [==============================] - 1s 871us/step - loss: 10311.0967 - accuracy: 0.4416\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 101171.9310 - accuracy: 0.5152\n",
      "473/473 [==============================] - 1s 819us/step - loss: 6291.2900 - accuracy: 0.5787\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 58350.0793 - accuracy: 0.5167\n",
      "473/473 [==============================] - 1s 968us/step - loss: 1164.7955 - accuracy: 0.5588\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 53155.8998 - accuracy: 0.5298\n",
      "473/473 [==============================] - 1s 908us/step - loss: 776.4113 - accuracy: 0.6733\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 76733.4918 - accuracy: 0.5250\n",
      "473/473 [==============================] - 1s 890us/step - loss: 3804.6133 - accuracy: 0.6208\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 64571.1618 - accuracy: 0.5140\n",
      "473/473 [==============================] - 1s 877us/step - loss: 1354.1819 - accuracy: 0.4755\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 94630.1870 - accuracy: 0.5142\n",
      "473/473 [==============================] - 1s 914us/step - loss: 116.7272 - accuracy: 0.4442\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 54548.2964 - accuracy: 0.5131\n",
      "473/473 [==============================] - 1s 954us/step - loss: 2463.8789 - accuracy: 0.6497\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 65167.8273 - accuracy: 0.5199\n",
      "473/473 [==============================] - 1s 883us/step - loss: 3186.7307 - accuracy: 0.5645\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 53318.9715 - accuracy: 0.5216\n",
      "473/473 [==============================] - 1s 898us/step - loss: 2651.8623 - accuracy: 0.5188\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 82829.6269 - accuracy: 0.5248\n",
      "473/473 [==============================] - 1s 819us/step - loss: 6115.6104 - accuracy: 0.5584\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 84981.6006 - accuracy: 0.5200\n",
      "473/473 [==============================] - 1s 881us/step - loss: 8840.5596 - accuracy: 0.4264\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 73568.4393 - accuracy: 0.5171\n",
      "473/473 [==============================] - 1s 829us/step - loss: 2927.9375 - accuracy: 0.6316\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 59228.1703 - accuracy: 0.5238\n",
      "473/473 [==============================] - 1s 838us/step - loss: 1796.7415 - accuracy: 0.5645\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 60489.3081 - accuracy: 0.5176\n",
      "473/473 [==============================] - 1s 995us/step - loss: 2474.2505 - accuracy: 0.5899\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 56676.6379 - accuracy: 0.5297\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 2333.2419 - accuracy: 0.4915\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 61813.7209 - accuracy: 0.5286\n",
      "473/473 [==============================] - 1s 914us/step - loss: 1081.7860 - accuracy: 0.6747\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 53283.6078 - accuracy: 0.5196\n",
      "473/473 [==============================] - 1s 955us/step - loss: 3880.4360 - accuracy: 0.6455\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 71978.9112 - accuracy: 0.5311\n",
      "473/473 [==============================] - 1s 935us/step - loss: 6266.0244 - accuracy: 0.4689\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 50575.8831 - accuracy: 0.5264\n",
      "473/473 [==============================] - 1s 815us/step - loss: 2113.5242 - accuracy: 0.5671\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 54875.0429 - accuracy: 0.5195\n",
      "473/473 [==============================] - 1s 817us/step - loss: 3451.2952 - accuracy: 0.5283\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 89094.0630 - accuracy: 0.5177\n",
      "473/473 [==============================] - 1s 889us/step - loss: 2443.5977 - accuracy: 0.5723\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 79455.7379 - accuracy: 0.5251\n",
      "473/473 [==============================] - 1s 941us/step - loss: 2738.7258 - accuracy: 0.6662\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 45971.3810 - accuracy: 0.5086\n",
      "473/473 [==============================] - 1s 931us/step - loss: 950.5905 - accuracy: 0.5637\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 56101.9010 - accuracy: 0.5215\n",
      "473/473 [==============================] - 1s 904us/step - loss: 3466.2786 - accuracy: 0.6030\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 61419.3947 - accuracy: 0.5173\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 10031.9102 - accuracy: 0.6557\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 58355.5655 - accuracy: 0.5312\n",
      "473/473 [==============================] - 1s 944us/step - loss: 4122.5796 - accuracy: 0.5745\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 83271.2154 - accuracy: 0.5151\n",
      "473/473 [==============================] - 1s 933us/step - loss: 2225.5964 - accuracy: 0.6637\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 76530.7983 - accuracy: 0.5188: 0s - loss: 801\n",
      "473/473 [==============================] - 1s 943us/step - loss: 1884.4342 - accuracy: 0.5645\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 90847.8448 - accuracy: 0.5153\n",
      "473/473 [==============================] - 1s 993us/step - loss: 1322.3385 - accuracy: 0.6881\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 50239.9773 - accuracy: 0.5150\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 4139.4292 - accuracy: 0.6426\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 55652.4017 - accuracy: 0.5107\n",
      "473/473 [==============================] - 1s 963us/step - loss: 1328.7855 - accuracy: 0.6041\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 115255.0139 - accuracy: 0.5057\n",
      "473/473 [==============================] - 1s 836us/step - loss: 1368.3700 - accuracy: 0.6366\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 104841.4452 - accuracy: 0.5208\n",
      "473/473 [==============================] - 1s 819us/step - loss: 3206.0271 - accuracy: 0.5645\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 66589.3104 - accuracy: 0.5193\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 209.5912 - accuracy: 0.5840\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 171065.2184 - accuracy: 0.5175\n",
      "473/473 [==============================] - 1s 921us/step - loss: 7799.4678 - accuracy: 0.5990\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 47380.8825 - accuracy: 0.5200\n",
      "473/473 [==============================] - 1s 911us/step - loss: 6833.5537 - accuracy: 0.6146\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 95154.7409 - accuracy: 0.5188\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 1706.2198 - accuracy: 0.5588\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 63242.3852 - accuracy: 0.5187\n",
      "473/473 [==============================] - 1s 990us/step - loss: 1140.8727 - accuracy: 0.6433\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 58848.5003 - accuracy: 0.5062\n",
      "473/473 [==============================] - 1s 946us/step - loss: 161.0583 - accuracy: 0.5578\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 51711.5031 - accuracy: 0.5172\n",
      "473/473 [==============================] - 1s 928us/step - loss: 1114.6222 - accuracy: 0.5584\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 76950.0940 - accuracy: 0.5362\n",
      "473/473 [==============================] - 1s 948us/step - loss: 2635.9319 - accuracy: 0.4852\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 62303.1656 - accuracy: 0.5303\n",
      "473/473 [==============================] - 1s 941us/step - loss: 884.9855 - accuracy: 0.6366\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 56613.7422 - accuracy: 0.5023\n",
      "473/473 [==============================] - 1s 991us/step - loss: 1990.5764 - accuracy: 0.6153\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 65932.5643 - accuracy: 0.5216\n",
      "473/473 [==============================] - 1s 895us/step - loss: 1456.0497 - accuracy: 0.4879\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 61285.8795 - accuracy: 0.5354\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 97.1036 - accuracy: 0.5690\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 80191.6469 - accuracy: 0.5340\n",
      "473/473 [==============================] - 1s 857us/step - loss: 297.1512 - accuracy: 0.5766\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 54497.2006 - accuracy: 0.5077\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 1200.3782 - accuracy: 0.6578\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 97339.3110 - accuracy: 0.5186\n",
      "473/473 [==============================] - 1s 830us/step - loss: 816.6325 - accuracy: 0.6669\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 49422.6523 - accuracy: 0.5208\n",
      "473/473 [==============================] - 1s 975us/step - loss: 6534.3589 - accuracy: 0.5777\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 58299.1508 - accuracy: 0.4997\n",
      "473/473 [==============================] - 1s 1000us/step - loss: 2013.8153 - accuracy: 0.5584\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 61892.5524 - accuracy: 0.5230\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 2275.0103 - accuracy: 0.5745\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 72231.8143 - accuracy: 0.5110\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 630.5610 - accuracy: 0.5588\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 98221.5478 - accuracy: 0.5166\n",
      "473/473 [==============================] - 1s 949us/step - loss: 588.8325 - accuracy: 0.5645\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 59854.1667 - accuracy: 0.5311\n",
      "473/473 [==============================] - 1s 869us/step - loss: 10762.8496 - accuracy: 0.5671\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 79135.2756 - accuracy: 0.5222\n",
      "473/473 [==============================] - 1s 948us/step - loss: 2088.3774 - accuracy: 0.5960\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 51224.3228 - accuracy: 0.5283\n",
      "473/473 [==============================] - 1s 978us/step - loss: 3413.4785 - accuracy: 0.4255\n",
      "1891/1891 [==============================] - 5s 3ms/step - loss: 88293.1560 - accuracy: 0.5105\n",
      "473/473 [==============================] - 1s 829us/step - loss: 1418.4525 - accuracy: 0.5630\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 70939.7416 - accuracy: 0.5279\n",
      "473/473 [==============================] - 1s 828us/step - loss: 954.5955 - accuracy: 0.6678\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 73107.5928 - accuracy: 0.5247\n",
      "473/473 [==============================] - 1s 970us/step - loss: 3545.6880 - accuracy: 0.5671\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 50337.3665 - accuracy: 0.5105\n",
      "473/473 [==============================] - 1s 874us/step - loss: 731.3994 - accuracy: 0.5584\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 81643.4441 - accuracy: 0.5267\n",
      "473/473 [==============================] - 1s 997us/step - loss: 9538.2305 - accuracy: 0.4255\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 70163.3510 - accuracy: 0.5224\n",
      "473/473 [==============================] - 1s 1ms/step - loss: 82.5897 - accuracy: 0.6358\n",
      "1891/1891 [==============================] - 5s 2ms/step - loss: 72592.8690 - accuracy: 0.5143\n",
      "473/473 [==============================] - 1s 959us/step - loss: 7699.6597 - accuracy: 0.5231\n",
      "1891/1891 [==============================] - 6s 3ms/step - loss: 56644.5030 - accuracy: 0.5173\n",
      "473/473 [==============================] - 1s 871us/step - loss: 7967.4888 - accuracy: 0.5671\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 54911.2946 - accuracy: 0.5036\n",
      "237/237 [==============================] - 0s 926us/step - loss: 904.1667 - accuracy: 0.5584\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 51732.0085 - accuracy: 0.5191\n",
      "237/237 [==============================] - 0s 1000us/step - loss: 1295.0948 - accuracy: 0.5973\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 76577.2513 - accuracy: 0.5125\n",
      "237/237 [==============================] - 0s 982us/step - loss: 3505.2041 - accuracy: 0.5588\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 77758.7382 - accuracy: 0.5159\n",
      "237/237 [==============================] - 0s 897us/step - loss: 2674.5081 - accuracy: 0.4499\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 61744.4381 - accuracy: 0.5159\n",
      "237/237 [==============================] - 0s 903us/step - loss: 1655.9302 - accuracy: 0.5954\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 63494.9971 - accuracy: 0.5214\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 2501.9219 - accuracy: 0.5245\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 61718.9917 - accuracy: 0.5087\n",
      "237/237 [==============================] - 0s 933us/step - loss: 536.8542 - accuracy: 0.6011\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 69856.1568 - accuracy: 0.5120\n",
      "237/237 [==============================] - 0s 920us/step - loss: 6246.7944 - accuracy: 0.5588\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 86209.6893 - accuracy: 0.5139\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 2962.5444 - accuracy: 0.6547\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 52104.8598 - accuracy: 0.5193\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 7266.0171 - accuracy: 0.5671\n",
      "946/946 [==============================] - 4s 3ms/step - loss: 54214.3051 - accuracy: 0.5218\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1297.4801 - accuracy: 0.5584\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 78396.9937 - accuracy: 0.5254\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 5005.0552 - accuracy: 0.5186\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 58180.4970 - accuracy: 0.5294\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 8899.2314 - accuracy: 0.5588\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 69238.0913 - accuracy: 0.5210\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 3260.2583 - accuracy: 0.6272\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 59623.4719 - accuracy: 0.5254\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 5583.1387 - accuracy: 0.5671\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 105816.2813 - accuracy: 0.5239\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 16059.8682 - accuracy: 0.5584\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 71862.7106 - accuracy: 0.5061\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 3725.5168 - accuracy: 0.4285\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 63140.8945 - accuracy: 0.5147\n",
      "237/237 [==============================] - 0s 935us/step - loss: 3887.6099 - accuracy: 0.6540\n",
      "946/946 [==============================] - 4s 3ms/step - loss: 53576.8514 - accuracy: 0.5334\n",
      "237/237 [==============================] - 0s 921us/step - loss: 5983.0190 - accuracy: 0.5645\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 53993.2726 - accuracy: 0.5164\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 4655.5376 - accuracy: 0.4329\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 73896.7380 - accuracy: 0.5058\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1196.0730 - accuracy: 0.6667\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 97366.5112 - accuracy: 0.5233\n",
      "237/237 [==============================] - 0s 967us/step - loss: 8407.4424 - accuracy: 0.5745\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 71246.9158 - accuracy: 0.5049\n",
      "237/237 [==============================] - 0s 968us/step - loss: 8104.6826 - accuracy: 0.6349\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 91643.2581 - accuracy: 0.5212\n",
      "237/237 [==============================] - 0s 973us/step - loss: 1452.2028 - accuracy: 0.6746\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 58128.5473 - accuracy: 0.5008\n",
      "237/237 [==============================] - 0s 944us/step - loss: 223.6608 - accuracy: 0.5755\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 65761.3812 - accuracy: 0.5122\n",
      "237/237 [==============================] - 0s 870us/step - loss: 2088.8010 - accuracy: 0.6366\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 67391.5312 - accuracy: 0.5093\n",
      "237/237 [==============================] - 0s 870us/step - loss: 9891.8320 - accuracy: 0.5745\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 38721.0156 - accuracy: 0.5392\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1611.6685 - accuracy: 0.6041\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 57979.6329 - accuracy: 0.5075\n",
      "237/237 [==============================] - 0s 1000us/step - loss: 1868.9321 - accuracy: 0.6229\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 55506.1664 - accuracy: 0.5219\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 2426.1592 - accuracy: 0.6196\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 58339.9053 - accuracy: 0.5344\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 9826.7852 - accuracy: 0.5584\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 71715.6532 - accuracy: 0.5145\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 608.9821 - accuracy: 0.6722\n",
      "946/946 [==============================] - 4s 3ms/step - loss: 43570.5488 - accuracy: 0.5261\n",
      "237/237 [==============================] - 0s 946us/step - loss: 2126.9546 - accuracy: 0.6654\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 103125.2913 - accuracy: 0.5150\n",
      "237/237 [==============================] - 0s 903us/step - loss: 1562.5930 - accuracy: 0.5645\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 58413.1748 - accuracy: 0.5309\n",
      "237/237 [==============================] - 0s 868us/step - loss: 3410.3833 - accuracy: 0.5878\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 72800.7800 - accuracy: 0.5247\n",
      "237/237 [==============================] - 0s 879us/step - loss: 927.7416 - accuracy: 0.6612\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 64660.8584 - accuracy: 0.5037\n",
      "237/237 [==============================] - 0s 878us/step - loss: 3352.8899 - accuracy: 0.6036\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 76047.8383 - accuracy: 0.5249\n",
      "237/237 [==============================] - 0s 871us/step - loss: 80.6446 - accuracy: 0.5998\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 69395.7145 - accuracy: 0.5105\n",
      "237/237 [==============================] - 0s 862us/step - loss: 1691.4731 - accuracy: 0.6293\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 63316.5157 - accuracy: 0.5206\n",
      "237/237 [==============================] - 0s 923us/step - loss: 2014.9655 - accuracy: 0.4380\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 55861.0101 - accuracy: 0.5040\n",
      "237/237 [==============================] - 0s 869us/step - loss: 89.1884 - accuracy: 0.6007\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 42077.2284 - accuracy: 0.5068\n",
      "237/237 [==============================] - 0s 879us/step - loss: 7944.0625 - accuracy: 0.4941\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 54658.9168 - accuracy: 0.5110\n",
      "237/237 [==============================] - 0s 940us/step - loss: 489.3869 - accuracy: 0.6654\n",
      "946/946 [==============================] - 3s 2ms/step - loss: 95603.9464 - accuracy: 0.5240\n",
      "237/237 [==============================] - 0s 826us/step - loss: 1394.8210 - accuracy: 0.6153\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 60175.1943 - accuracy: 0.5237\n",
      "237/237 [==============================] - 0s 901us/step - loss: 11932.6299 - accuracy: 0.6162\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 54627.6057 - accuracy: 0.5303\n",
      "237/237 [==============================] - 0s 948us/step - loss: 1866.3611 - accuracy: 0.6299\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 60321.0719 - accuracy: 0.5288\n",
      "237/237 [==============================] - 0s 871us/step - loss: 877.3196 - accuracy: 0.6768\n",
      "946/946 [==============================] - 3s 2ms/step - loss: 66098.6208 - accuracy: 0.5132\n",
      "237/237 [==============================] - 0s 822us/step - loss: 2505.1064 - accuracy: 0.6662\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 75166.5799 - accuracy: 0.5270\n",
      "237/237 [==============================] - 0s 864us/step - loss: 986.9056 - accuracy: 0.5095\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 80432.6756 - accuracy: 0.5162\n",
      "237/237 [==============================] - 0s 888us/step - loss: 4393.6421 - accuracy: 0.5675\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 97806.0195 - accuracy: 0.5221\n",
      "237/237 [==============================] - 0s 900us/step - loss: 7409.8501 - accuracy: 0.5584\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 59840.3271 - accuracy: 0.5102\n",
      "237/237 [==============================] - 0s 882us/step - loss: 3458.7966 - accuracy: 0.5745\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 142839.6925 - accuracy: 0.5076\n",
      "237/237 [==============================] - 0s 872us/step - loss: 978.4503 - accuracy: 0.6024\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 52335.4835 - accuracy: 0.5149\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 5211.4863 - accuracy: 0.5556\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 51698.0428 - accuracy: 0.5181\n",
      "237/237 [==============================] - 0s 887us/step - loss: 6708.1279 - accuracy: 0.6022\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 53238.8967 - accuracy: 0.5154\n",
      "237/237 [==============================] - 0s 868us/step - loss: 84.4136 - accuracy: 0.5728\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 51123.6578 - accuracy: 0.5060\n",
      "237/237 [==============================] - 0s 862us/step - loss: 2622.8792 - accuracy: 0.5745\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 54661.8595 - accuracy: 0.5046\n",
      "237/237 [==============================] - 0s 897us/step - loss: 195.2585 - accuracy: 0.6658\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 59352.8809 - accuracy: 0.5139\n",
      "237/237 [==============================] - 0s 874us/step - loss: 4540.5161 - accuracy: 0.5675\n",
      "946/946 [==============================] - 3s 2ms/step - loss: 55149.9446 - accuracy: 0.5239\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 479.9200 - accuracy: 0.6750\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 47034.5209 - accuracy: 0.5051\n",
      "237/237 [==============================] - 0s 900us/step - loss: 51.8020 - accuracy: 0.5753\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 60479.4324 - accuracy: 0.5358\n",
      "237/237 [==============================] - 0s 862us/step - loss: 500.5988 - accuracy: 0.6764\n",
      "946/946 [==============================] - 3s 2ms/step - loss: 53046.7846 - accuracy: 0.5128\n",
      "237/237 [==============================] - 0s 865us/step - loss: 851.9014 - accuracy: 0.6646\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 67590.3603 - accuracy: 0.5315\n",
      "237/237 [==============================] - 0s 872us/step - loss: 917.9066 - accuracy: 0.6009\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 73818.3620 - accuracy: 0.5063\n",
      "237/237 [==============================] - 0s 866us/step - loss: 4232.9668 - accuracy: 0.6085\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 61985.4725 - accuracy: 0.5176\n",
      "237/237 [==============================] - 0s 874us/step - loss: 15127.3096 - accuracy: 0.5584\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 63214.6315 - accuracy: 0.5134\n",
      "237/237 [==============================] - 0s 854us/step - loss: 4295.1899 - accuracy: 0.6392\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 55292.7555 - accuracy: 0.5254\n",
      "237/237 [==============================] - 0s 856us/step - loss: 598.6871 - accuracy: 0.5588\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 70498.3809 - accuracy: 0.5138\n",
      "237/237 [==============================] - 0s 873us/step - loss: 2200.7898 - accuracy: 0.6009\n",
      "946/946 [==============================] - 3s 2ms/step - loss: 58791.0866 - accuracy: 0.5274\n",
      "237/237 [==============================] - 0s 864us/step - loss: 476.4501 - accuracy: 0.6009\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 51151.1165 - accuracy: 0.5202\n",
      "237/237 [==============================] - 0s 928us/step - loss: 23496.6992 - accuracy: 0.5584\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 48164.3939 - accuracy: 0.5091\n",
      "237/237 [==============================] - 0s 890us/step - loss: 510.9922 - accuracy: 0.6772\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 52234.3432 - accuracy: 0.5150\n",
      "237/237 [==============================] - 0s 881us/step - loss: 1575.8333 - accuracy: 0.5588\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 76458.1041 - accuracy: 0.5150\n",
      "237/237 [==============================] - 0s 867us/step - loss: 607.4739 - accuracy: 0.5950\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 50477.0471 - accuracy: 0.5145\n",
      "237/237 [==============================] - 0s 863us/step - loss: 1216.3337 - accuracy: 0.5963\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 64255.8729 - accuracy: 0.5147\n",
      "237/237 [==============================] - 0s 858us/step - loss: 1734.7970 - accuracy: 0.6087\n",
      "946/946 [==============================] - 3s 2ms/step - loss: 115757.9026 - accuracy: 0.5157\n",
      "237/237 [==============================] - 0s 833us/step - loss: 2943.2065 - accuracy: 0.4255\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 62580.6463 - accuracy: 0.5136\n",
      "237/237 [==============================] - 0s 881us/step - loss: 364.7301 - accuracy: 0.6646\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 64183.7916 - accuracy: 0.5181\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1591.3978 - accuracy: 0.6153\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 66856.8612 - accuracy: 0.5106\n",
      "237/237 [==============================] - 0s 874us/step - loss: 3611.3503 - accuracy: 0.5912\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 52942.5421 - accuracy: 0.5111\n",
      "237/237 [==============================] - 0s 873us/step - loss: 1310.6697 - accuracy: 0.6536\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 63260.9684 - accuracy: 0.5167\n",
      "237/237 [==============================] - 0s 891us/step - loss: 1350.9202 - accuracy: 0.5918\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 61733.0658 - accuracy: 0.5118\n",
      "237/237 [==============================] - 0s 877us/step - loss: 3219.5347 - accuracy: 0.6332\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 75321.2466 - accuracy: 0.5169\n",
      "237/237 [==============================] - 0s 888us/step - loss: 3232.6411 - accuracy: 0.4355\n",
      "946/946 [==============================] - 3s 2ms/step - loss: 104163.2425 - accuracy: 0.5139\n",
      "237/237 [==============================] - 0s 867us/step - loss: 15608.3369 - accuracy: 0.5671\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 42152.8665 - accuracy: 0.5042\n",
      "237/237 [==============================] - 0s 879us/step - loss: 2743.8125 - accuracy: 0.6375\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 79962.1718 - accuracy: 0.5241\n",
      "237/237 [==============================] - 0s 879us/step - loss: 635.0789 - accuracy: 0.6785\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 41032.0524 - accuracy: 0.5269\n",
      "237/237 [==============================] - 0s 858us/step - loss: 994.0730 - accuracy: 0.5956\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 78857.0213 - accuracy: 0.5230\n",
      "237/237 [==============================] - 0s 872us/step - loss: 2016.7037 - accuracy: 0.6754\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 54977.6514 - accuracy: 0.5239\n",
      "237/237 [==============================] - 0s 891us/step - loss: 580.5911 - accuracy: 0.6873\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 58362.2140 - accuracy: 0.5046\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 6027.3765 - accuracy: 0.5279\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 71761.3300 - accuracy: 0.5005\n",
      "119/119 [==============================] - 0s 992us/step - loss: 820.7383 - accuracy: 0.5943\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 57193.9015 - accuracy: 0.4978\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2764.0020 - accuracy: 0.5415\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 75747.5551 - accuracy: 0.5214\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 1406.1411 - accuracy: 0.6627\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 59388.6040 - accuracy: 0.5072\n",
      "119/119 [==============================] - 0s 995us/step - loss: 855.1390 - accuracy: 0.5671\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 48955.3948 - accuracy: 0.5050\n",
      "119/119 [==============================] - 0s 996us/step - loss: 6134.4097 - accuracy: 0.5643\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 77302.4764 - accuracy: 0.5143\n",
      "119/119 [==============================] - 0s 990us/step - loss: 1147.7637 - accuracy: 0.5939\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 52261.2049 - accuracy: 0.5136\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 498.0488 - accuracy: 0.5588\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 60109.8453 - accuracy: 0.5105\n",
      "119/119 [==============================] - 0s 966us/step - loss: 1556.3800 - accuracy: 0.6741\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 61494.9107 - accuracy: 0.5139\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2094.8442 - accuracy: 0.5074\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 99626.0065 - accuracy: 0.5091\n",
      "119/119 [==============================] - 0s 993us/step - loss: 7135.3340 - accuracy: 0.5584\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 78056.7864 - accuracy: 0.5187\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5117.4043 - accuracy: 0.6612\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 65146.9623 - accuracy: 0.5129\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 14748.3301 - accuracy: 0.5588\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 66274.6492 - accuracy: 0.5024\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2911.4612 - accuracy: 0.6014\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 57661.3447 - accuracy: 0.5364\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 14510.2734 - accuracy: 0.5616\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 42485.4293 - accuracy: 0.5056\n",
      "119/119 [==============================] - 0s 979us/step - loss: 7116.1802 - accuracy: 0.4619\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 51888.8699 - accuracy: 0.5200\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2446.5435 - accuracy: 0.6519\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 66808.1291 - accuracy: 0.5099\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 10557.5029 - accuracy: 0.6091\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 70403.5097 - accuracy: 0.5127\n",
      "119/119 [==============================] - 0s 997us/step - loss: 1163.0358 - accuracy: 0.6289\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 54804.9542 - accuracy: 0.5080\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 682.4486 - accuracy: 0.4985\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 43021.6024 - accuracy: 0.5006\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 9376.1914 - accuracy: 0.5313\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 50072.0041 - accuracy: 0.4929\n",
      "119/119 [==============================] - 0s 998us/step - loss: 5502.9678 - accuracy: 0.5745\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 63708.5992 - accuracy: 0.4840\n",
      "119/119 [==============================] - 0s 996us/step - loss: 4136.2305 - accuracy: 0.5588\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 67120.6928 - accuracy: 0.5127\n",
      "119/119 [==============================] - 0s 989us/step - loss: 4323.0034 - accuracy: 0.5772\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 58419.7213 - accuracy: 0.5122\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4096.0815 - accuracy: 0.5671\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 51629.8250 - accuracy: 0.5066\n",
      "119/119 [==============================] - 0s 997us/step - loss: 3567.0745 - accuracy: 0.6113\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 65498.4273 - accuracy: 0.5138\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 525.7558 - accuracy: 0.6650\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 51272.2786 - accuracy: 0.5106\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2242.6919 - accuracy: 0.6197\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 101483.1464 - accuracy: 0.5116\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 1471.8900 - accuracy: 0.5645\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 46655.2502 - accuracy: 0.5055\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 9333.5576 - accuracy: 0.5671\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 63380.2428 - accuracy: 0.5123\n",
      "119/119 [==============================] - 0s 994us/step - loss: 28281.3340 - accuracy: 0.5584\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 56177.7111 - accuracy: 0.5183\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 9843.7959 - accuracy: 0.5745\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 59274.4841 - accuracy: 0.5226\n",
      "119/119 [==============================] - 0s 992us/step - loss: 5020.0332 - accuracy: 0.6070\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 69535.7423 - accuracy: 0.5006\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 1919.4448 - accuracy: 0.5963\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 47879.9781 - accuracy: 0.5052\n",
      "119/119 [==============================] - 0s 994us/step - loss: 1394.5204 - accuracy: 0.6221\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 52186.6242 - accuracy: 0.4980\n",
      "119/119 [==============================] - 0s 990us/step - loss: 6266.5942 - accuracy: 0.5795\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 59818.2119 - accuracy: 0.5118\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 24211.4844 - accuracy: 0.4814\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 48244.4891 - accuracy: 0.4981\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 979.4909 - accuracy: 0.5588\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 57506.9979 - accuracy: 0.5134\n",
      "119/119 [==============================] - 0s 993us/step - loss: 13335.7793 - accuracy: 0.5645\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 72665.9741 - accuracy: 0.5139\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2521.0803 - accuracy: 0.6873\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 44625.2286 - accuracy: 0.5148\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2527.9775 - accuracy: 0.5584\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 81232.7625 - accuracy: 0.5193\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 1408.3383 - accuracy: 0.5745\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 51542.7886 - accuracy: 0.5145\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 8937.5645 - accuracy: 0.5588\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 46896.1757 - accuracy: 0.5103\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2170.3162 - accuracy: 0.4388\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 49474.1450 - accuracy: 0.5099\n",
      "119/119 [==============================] - 0s 996us/step - loss: 7408.3428 - accuracy: 0.5612\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 78571.1143 - accuracy: 0.5162\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2235.1367 - accuracy: 0.4945\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 77104.2577 - accuracy: 0.5004\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 388.4927 - accuracy: 0.5766\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 50831.1791 - accuracy: 0.5124\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2214.0977 - accuracy: 0.6561\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 68180.5183 - accuracy: 0.5153\n",
      "119/119 [==============================] - 0s 995us/step - loss: 4518.9824 - accuracy: 0.5493\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 62860.4514 - accuracy: 0.5109\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5347.7593 - accuracy: 0.5671\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 50445.5723 - accuracy: 0.5129\n",
      "119/119 [==============================] - 0s 986us/step - loss: 5019.1924 - accuracy: 0.6459\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 70290.7192 - accuracy: 0.5085\n",
      "119/119 [==============================] - 0s 984us/step - loss: 10653.2676 - accuracy: 0.5745\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 54342.0997 - accuracy: 0.5065\n",
      "119/119 [==============================] - 0s 978us/step - loss: 2813.9148 - accuracy: 0.5791\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 50509.4883 - accuracy: 0.5131\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 543.4978 - accuracy: 0.6788\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 70380.1475 - accuracy: 0.5049\n",
      "119/119 [==============================] - 0s 974us/step - loss: 1239.2123 - accuracy: 0.6119\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 76702.9801 - accuracy: 0.5126\n",
      "119/119 [==============================] - 0s 991us/step - loss: 8400.9023 - accuracy: 0.5960\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 59865.5917 - accuracy: 0.5151\n",
      "119/119 [==============================] - 0s 990us/step - loss: 1943.9869 - accuracy: 0.6777\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 45442.9121 - accuracy: 0.5048\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4923.4233 - accuracy: 0.5905\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 48093.8978 - accuracy: 0.5004\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 6946.4517 - accuracy: 0.5641\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 56731.5654 - accuracy: 0.5228\n",
      "119/119 [==============================] - 0s 993us/step - loss: 8366.9062 - accuracy: 0.5133\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 42535.6339 - accuracy: 0.5127\n",
      "119/119 [==============================] - 0s 988us/step - loss: 10443.1123 - accuracy: 0.5778\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 50857.6853 - accuracy: 0.5156\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 832.5375 - accuracy: 0.6789\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 66756.0865 - accuracy: 0.5159\n",
      "119/119 [==============================] - 0s 985us/step - loss: 5584.4238 - accuracy: 0.5533\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 63238.5442 - accuracy: 0.5107\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2202.1055 - accuracy: 0.6225\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 67113.1245 - accuracy: 0.5027\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 464.1593 - accuracy: 0.6572\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 62207.4251 - accuracy: 0.4987\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5750.3638 - accuracy: 0.5842\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 62341.2639 - accuracy: 0.5081\n",
      "119/119 [==============================] - 0s 991us/step - loss: 11393.9277 - accuracy: 0.4539\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 78869.2589 - accuracy: 0.5099\n",
      "119/119 [==============================] - 0s 943us/step - loss: 4398.9585 - accuracy: 0.5990\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 58455.5844 - accuracy: 0.5139\n",
      "119/119 [==============================] - 0s 979us/step - loss: 5941.2524 - accuracy: 0.5028\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 64957.8171 - accuracy: 0.5104\n",
      "119/119 [==============================] - 0s 987us/step - loss: 2971.3594 - accuracy: 0.5904\n",
      "473/473 [==============================] - 3s 4ms/step - loss: 42903.8031 - accuracy: 0.5168\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 319.1751 - accuracy: 0.5584\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 78152.8673 - accuracy: 0.5167\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 29045.2754 - accuracy: 0.5745\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 77020.7248 - accuracy: 0.5064\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 3605.7966 - accuracy: 0.6231\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 63088.1164 - accuracy: 0.5077\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 447.8061 - accuracy: 0.6466\n",
      "473/473 [==============================] - 3s 4ms/step - loss: 67908.4175 - accuracy: 0.5078\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 10248.6338 - accuracy: 0.5083\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 58811.4510 - accuracy: 0.5229\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 14527.6787 - accuracy: 0.4962\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 62218.8076 - accuracy: 0.5235\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7522.8657 - accuracy: 0.4966\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 57088.8221 - accuracy: 0.5053\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2899.4690 - accuracy: 0.5588\n",
      "473/473 [==============================] - 3s 4ms/step - loss: 75412.9655 - accuracy: 0.5194\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 3315.0229 - accuracy: 0.6111\n",
      "473/473 [==============================] - 3s 4ms/step - loss: 63958.1952 - accuracy: 0.5206\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 3975.0801 - accuracy: 0.6196\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 52289.4381 - accuracy: 0.5133\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2879.9773 - accuracy: 0.5681\n",
      "473/473 [==============================] - 3s 4ms/step - loss: 82743.5988 - accuracy: 0.5129\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5884.0537 - accuracy: 0.5080\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 59920.7601 - accuracy: 0.4999\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 13203.4199 - accuracy: 0.5588\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 68541.8458 - accuracy: 0.5188\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 6626.8022 - accuracy: 0.5781\n",
      "473/473 [==============================] - 3s 4ms/step - loss: 64275.0541 - accuracy: 0.5054\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2812.2039 - accuracy: 0.5671\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 64048.6064 - accuracy: 0.4987\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4779.0459 - accuracy: 0.6464\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 62433.5654 - accuracy: 0.5169\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4142.4927 - accuracy: 0.5745\n",
      "473/473 [==============================] - 3s 4ms/step - loss: 87590.7280 - accuracy: 0.5190\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 8720.1426 - accuracy: 0.5588\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 52809.8979 - accuracy: 0.5202\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 2390.7100 - accuracy: 0.6703\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 52194.4616 - accuracy: 0.5179\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4310.5513 - accuracy: 0.4435\n",
      "1182/1182 [==============================] - 4s 3ms/step - loss: 59026.8287 - accuracy: 0.5175\n",
      "{'batch_size': 10, 'init': 'uniform', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "507/507 [==============================] - 1s 1ms/step - loss: 4067.2205 - accuracy: 0.5647\n",
      "dnn: 0.5646594166755676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:2240: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:2240: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.47%, Logloss: nan\n",
      "946/946 [==============================] - 4s 3ms/step - loss: 80873.3693 - accuracy: 0.5258\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 1668.0912 - accuracy: 0.5161\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 62255.9231 - accuracy: 0.5072\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 12581.3975 - accuracy: 0.5745\n",
      "946/946 [==============================] - 3s 3ms/step - loss: 81329.9227 - accuracy: 0.5259\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 2700.2883 - accuracy: 0.6354\n",
      "946/946 [==============================] - 4s 3ms/step - loss: 59297.7810 - accuracy: 0.5322\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 4102.1221 - accuracy: 0.5645\n",
      "946/946 [==============================] - 4s 3ms/step - loss: 54545.3840 - accuracy: 0.5191\n",
      "237/237 [==============================] - 0s 1ms/step - loss: 2335.1548 - accuracy: 0.5912\n",
      "0.5763245224952698\n"
     ]
    }
   ],
   "source": [
    "dnn_model = dnn(x_train, y_train, x_validation, y_validation)\n",
    "test_model(dnn_model,x_validation,y_validation)\n",
    "cross_val(dnn_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-4c2ddda5cc14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_featu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"Opportunity_ID\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_featu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbest_featu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Opportunity_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-824fd1eb28c8>\u001b[0m in \u001b[0;36mbest_features\u001b[0;34m(model, train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbest_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Feature\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Importance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Importance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Feature\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "best_featu = best_features(dnn_model,X_train)\n",
    "if \"Opportunity_ID\" not in best_featu: \n",
    "    best_featu.append(\"Opportunity_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_pred = dnn_model.predict_proba(X_test)[:,1]\n",
    "submission_dnn = pd.DataFrame(data={'Opportunity_ID':X_test['Opportunity_ID'], 'Target': y_pred})\n",
    "submission_dnn = submission_dnn.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_dnn.to_csv('../submits/dnn_with_cat_boost_encoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_best_features = X_train.loc[:,best_featu]\n",
    "X_test_best_features = X_test.loc[:,best_featu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_best_train, x_best_validation, y_best_train, y_best_validation = train_test_split(X_train_best_features, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model_2 = dnn(x_best_train, y_best_train, x_best_validation, y_best_validation)\n",
    "test_model(dnn_model_2,x_best_validation,y_best_validation)\n",
    "cross_val(dnn_model_2, x_best_train, y_best_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = dnn_model_2.predict_proba(X_test_best_features)[:,1]\n",
    "submission_dnn_2 = pd.DataFrame(data={'Opportunity_ID':X_test_best_features['Opportunity_ID'], 'Target': y_pred_2})\n",
    "submission_dnn_2 = submission_dnn_2.groupby(\"Opportunity_ID\").agg({\"Target\":\"mean\"}).reset_index()\n",
    "submission_dnn_2.to_csv('../submits/dnn_best_features_with_cat_boost_encoding.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
