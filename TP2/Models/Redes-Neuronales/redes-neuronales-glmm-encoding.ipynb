{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, accuracy_score, make_scorer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from keras.models import Sequential, Input\n",
    "from keras.layers import  Dropout, Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../Feature_Encoding/data/train_glmm_encoding.csv')\n",
    "df_test = pd.read_csv('../../Feature_Encoding/data/test_glmm_encoding.csv')\n",
    "train = pd.read_csv('../../Feature_Engineering/data/other-cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_test.columns.tolist():\n",
    "    df_test[column] = df_test[column].fillna(0)  \n",
    "\n",
    "df_test= df_test.replace('', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, x_train, y_train):\n",
    "    score_cross_val = model_selection.cross_val_score(model, x_train, y_train, cv=5)\n",
    "    print(score_cross_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal profunda - https://keras.io/guides/sequential_model/\n",
    "# nFeatures -> cantidad de features (columnas de set)\n",
    "# nClasses -> cantidad de clases que pueden ser (2 -> lost vs won)\n",
    "def DNN_model_bin(optimizer='rmsprop',init='glorot_uniform'):\n",
    "    node = 512\n",
    "    nClasses = 2\n",
    "    dropout=0.5\n",
    "    nFeatures = 185\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(node,input_dim=nFeatures,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,4):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# Red neuronal profunda - https://keras.io/guides/sequential_model/\n",
    "# nFeatures -> cantidad de features (columnas de set)\n",
    "# nClasses -> cantidad de clases que pueden ser (2 -> lost vs won)\n",
    "def DNN_model(optimizer='rmsprop',init='glorot_uniform'):\n",
    "    node = 512\n",
    "    nClasses = 2\n",
    "    dropout=0.5\n",
    "    nFeatures = 55\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(node,input_dim=nFeatures,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(0,4):\n",
    "        model.add(Dense(node,input_dim=node,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(x_train, y_train, x_validation, y_validation):\n",
    "    keras_model = KerasClassifier(build_fn=DNN_model)\n",
    "    optimizers = ['rmsprop', 'adam']\n",
    "    init = ['glorot_uniform', 'normal', 'uniform']\n",
    "    epochs = [50, 100, 150]\n",
    "    batches = batches = [5, 10, 20]\n",
    "    param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "    dnn_gs = GridSearchCV(keras_model, param_grid=param_grid)\n",
    "    dnn_gs.fit(x_train, y_train)\n",
    "    dnn_best = dnn_gs.best_estimator_\n",
    "    print(dnn_gs.best_params_)\n",
    "    print('dnn: {}'.format(dnn_best.score(x_validation, y_validation)))\n",
    "    return dnn_best\n",
    "\n",
    "def dnn_bin(x_train, y_train, x_validation, y_validation):\n",
    "    keras_model = KerasClassifier(build_fn=DNN_model_bin)\n",
    "    optimizers = ['rmsprop', 'adam']\n",
    "    init = ['glorot_uniform', 'normal', 'uniform']\n",
    "    epochs = [50, 100, 150]\n",
    "    batches = batches = [5, 10, 20]\n",
    "    param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "    dnn_gs = GridSearchCV(keras_model, param_grid=param_grid)\n",
    "    dnn_gs.fit(x_train, y_train)\n",
    "    dnn_best = dnn_gs.best_estimator_\n",
    "    print(dnn_gs.best_params_)\n",
    "    print('dnn: {}'.format(dnn_best.score(x_validation, y_validation)))\n",
    "    return dnn_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    predictions = model.predict_proba(x_test)[:,1]\n",
    "    logloss = log_loss(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions.round())\n",
    "    print(\"Accuracy: %.2f%%, Logloss: %.2f\" % (accuracy*100.0, logloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Target\n",
    "x_train, x_validation, y_train, y_validation = model_selection.train_test_split(df_train, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 41s 20ms/step - loss: 55715.3351 - accuracy: 0.5167\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 3851.6780 - accuracy: 0.6772\n",
      "1891/1891 [==============================] - 49s 25ms/step - loss: 87460.1445 - accuracy: 0.5117\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 3009.7302 - accuracy: 0.6282\n",
      "1891/1891 [==============================] - 47s 24ms/step - loss: 59720.9745 - accuracy: 0.5245\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 914.7814 - accuracy: 0.4222\n",
      "1891/1891 [==============================] - 44s 23ms/step - loss: 76799.7358 - accuracy: 0.51150s - loss: 76921.7582 - accuracy\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 1027.5111 - accuracy: 0.6344\n",
      "1891/1891 [==============================] - 50s 26ms/step - loss: 100824.1346 - accuracy: 0.5203\n",
      "473/473 [==============================] - 4s 7ms/step - loss: 2458.0884 - accuracy: 0.6483\n",
      "1891/1891 [==============================] - 51s 26ms/step - loss: 87059.0585 - accuracy: 0.5220\n",
      "473/473 [==============================] - 3s 7ms/step - loss: 937.4870 - accuracy: 0.6823\n",
      "1891/1891 [==============================] - 47s 24ms/step - loss: 58573.2253 - accuracy: 0.5151\n",
      "473/473 [==============================] - 3s 5ms/step - loss: 1428.7118 - accuracy: 0.6307\n",
      "1891/1891 [==============================] - 36s 19ms/step - loss: 53769.5888 - accuracy: 0.5049\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 7006.4648 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 30s 16ms/step - loss: 51574.0131 - accuracy: 0.5177\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 1329.9617 - accuracy: 0.5565\n",
      "1891/1891 [==============================] - 29s 15ms/step - loss: 79009.8742 - accuracy: 0.5172\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 9319.1797 - accuracy: 0.6712\n",
      "1891/1891 [==============================] - 33s 17ms/step - loss: 51488.6254 - accuracy: 0.5109\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 13910.0371 - accuracy: 0.5804\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 55048.7522 - accuracy: 0.5283\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1460.1932 - accuracy: 0.6464\n",
      "1891/1891 [==============================] - 26s 14ms/step - loss: 56810.4272 - accuracy: 0.5227\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 5295.8638 - accuracy: 0.6206\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 70503.9213 - accuracy: 0.5386\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 4567.7383 - accuracy: 0.5565\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 61724.6042 - accuracy: 0.5219\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 1172.5624 - accuracy: 0.6691\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 60130.1699 - accuracy: 0.5124\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 4246.4351 - accuracy: 0.4860\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 76085.6951 - accuracy: 0.5156\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 1418.9735 - accuracy: 0.5592\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 50394.3714 - accuracy: 0.5223\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 4487.9302 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 55824.7646 - accuracy: 0.5008\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 7656.2183 - accuracy: 0.5565\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 65936.9523 - accuracy: 0.5314\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 516.2418 - accuracy: 0.6720\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 80435.6393 - accuracy: 0.5220\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 19327.4160 - accuracy: 0.5635\n",
      "1891/1891 [==============================] - 27s 14ms/step - loss: 40449.3307 - accuracy: 0.5179\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 3120.7788 - accuracy: 0.6641\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 46726.8098 - accuracy: 0.5276\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 4009.5593 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 59768.2555 - accuracy: 0.5201\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 755.5669 - accuracy: 0.6441\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 118552.6482 - accuracy: 0.5071\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1975.8151 - accuracy: 0.5662\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 53646.7545 - accuracy: 0.5132\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 4899.8306 - accuracy: 0.5635\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 75151.3384 - accuracy: 0.5133\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1576.0463 - accuracy: 0.5592\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 51490.2816 - accuracy: 0.5325\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 2948.4138 - accuracy: 0.6248\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 63498.9072 - accuracy: 0.5241\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 3964.2036 - accuracy: 0.6805\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 63958.0117 - accuracy: 0.5155\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 11299.8213 - accuracy: 0.5662\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 53626.2944 - accuracy: 0.5167\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 19490.0547 - accuracy: 0.5635\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 52475.1796 - accuracy: 0.5077\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 197.4628 - accuracy: 0.5880\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 60522.9117 - accuracy: 0.5344\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 3413.2273 - accuracy: 0.6912\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 104006.8317 - accuracy: 0.5104\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 6420.4121 - accuracy: 0.4435\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 65796.5160 - accuracy: 0.5335\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 4744.3501 - accuracy: 0.6183\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 73789.3257 - accuracy: 0.5238\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 17165.4844 - accuracy: 0.5635\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 85949.7487 - accuracy: 0.5188\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1871.9633 - accuracy: 0.6282\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 75544.7643 - accuracy: 0.5327\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1502.3175 - accuracy: 0.6925\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 55305.8276 - accuracy: 0.5168\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1311.9320 - accuracy: 0.5569\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 71866.5311 - accuracy: 0.5184\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 5348.2573 - accuracy: 0.5307\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 48694.7908 - accuracy: 0.5313\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 2251.3679 - accuracy: 0.6531\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 56178.5980 - accuracy: 0.5198\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 5192.5894 - accuracy: 0.6019\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 52072.5231 - accuracy: 0.5255\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 4497.5298 - accuracy: 0.5770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 24s 12ms/step - loss: 91676.0083 - accuracy: 0.5368\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 1631.5074 - accuracy: 0.5658\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 67811.0734 - accuracy: 0.5149\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 496.9197 - accuracy: 0.6691\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 54070.3151 - accuracy: 0.5126\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 40139.1172 - accuracy: 0.5635\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 92705.6079 - accuracy: 0.5166\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 1756.6176 - accuracy: 0.5601\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 80575.3486 - accuracy: 0.5203\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 9259.3623 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 104523.2786 - accuracy: 0.5238\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1543.4469 - accuracy: 0.5565\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 81193.4492 - accuracy: 0.5281\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 2048.1072 - accuracy: 0.6293\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 40421.6180 - accuracy: 0.5186\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 833.0167 - accuracy: 0.6108\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 62804.0097 - accuracy: 0.5313\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 1820.9059 - accuracy: 0.5592\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 83288.8796 - accuracy: 0.5245\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 19325.2090 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 51323.4013 - accuracy: 0.5282\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 5731.3252 - accuracy: 0.5878\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 77773.1951 - accuracy: 0.5128\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 855.5871 - accuracy: 0.6449\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 60940.0048 - accuracy: 0.5210\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 3190.9280 - accuracy: 0.5986\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 59854.7450 - accuracy: 0.5360\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1929.3145 - accuracy: 0.5592\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 84164.7103 - accuracy: 0.5095\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 7329.8232 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 66379.7268 - accuracy: 0.5227\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 4705.4775 - accuracy: 0.5565\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 103838.4884 - accuracy: 0.5162\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1492.6187 - accuracy: 0.5662\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 90966.6312 - accuracy: 0.5098\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 372.3779 - accuracy: 0.6028\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 55715.1493 - accuracy: 0.5240\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 5238.0698 - accuracy: 0.5360\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 67903.2781 - accuracy: 0.5278\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 11012.2256 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 111138.7716 - accuracy: 0.5220\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1317.5637 - accuracy: 0.5565\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 91287.7685 - accuracy: 0.5245\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 13460.4229 - accuracy: 0.5662\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 82521.9021 - accuracy: 0.5303\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 4515.1470 - accuracy: 0.6409\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 92205.0760 - accuracy: 0.5169\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 1834.4968 - accuracy: 0.5592\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 119257.0627 - accuracy: 0.5209\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 1360.4490 - accuracy: 0.6980\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 79864.8702 - accuracy: 0.5225\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 4775.9434 - accuracy: 0.5565\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 99576.4639 - accuracy: 0.5221\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 1737.1711 - accuracy: 0.5163\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 55801.1293 - accuracy: 0.5185\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 6730.0879 - accuracy: 0.6265\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 68395.4316 - accuracy: 0.5249\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 3680.2649 - accuracy: 0.5939\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 82976.0353 - accuracy: 0.5207\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 3998.6028 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 74392.5049 - accuracy: 0.5235\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 19309.3262 - accuracy: 0.4460\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 120285.8227 - accuracy: 0.5285\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 3011.5388 - accuracy: 0.6242\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 67999.0896 - accuracy: 0.5216\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 390.3247 - accuracy: 0.6650\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 67693.0345 - accuracy: 0.5271\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 13455.3389 - accuracy: 0.5592\n",
      "1891/1891 [==============================] - 24s 13ms/step - loss: 59483.0458 - accuracy: 0.5201\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 1664.0192 - accuracy: 0.6950\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 74533.6178 - accuracy: 0.5134\n",
      "473/473 [==============================] - 1s 2ms/step - loss: 667.2109 - accuracy: 0.5692\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 98739.9529 - accuracy: 0.5253\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 688.2866 - accuracy: 0.6691\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 59439.7636 - accuracy: 0.5283\n",
      "473/473 [==============================] - 2s 4ms/step - loss: 1020.2900 - accuracy: 0.5635\n",
      "1891/1891 [==============================] - 25s 13ms/step - loss: 92835.0489 - accuracy: 0.5112\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 750.0140 - accuracy: 0.5592\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 51568.2368 - accuracy: 0.5111\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 5135.3413 - accuracy: 0.5778\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 34959.1938 - accuracy: 0.5133\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 125.1259 - accuracy: 0.6225\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 78044.5991 - accuracy: 0.5114\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 3006.0818 - accuracy: 0.6665\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 80434.5975 - accuracy: 0.5155\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 9057.5859 - accuracy: 0.6062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891/1891 [==============================] - 24s 12ms/step - loss: 58295.5378 - accuracy: 0.5173\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 1566.3105 - accuracy: 0.6557\n",
      "1891/1891 [==============================] - 24s 12ms/step - loss: 55464.5539 - accuracy: 0.5208\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 2436.8184 - accuracy: 0.6159\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 67004.3780 - accuracy: 0.5066\n",
      "473/473 [==============================] - 1s 3ms/step - loss: 2986.5491 - accuracy: 0.6653\n",
      "1891/1891 [==============================] - 23s 12ms/step - loss: 58053.5730 - accuracy: 0.5156\n",
      "473/473 [==============================] - 2s 3ms/step - loss: 80.2575 - accuracy: 0.5662\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 61054.9488 - accuracy: 0.5095\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3206.2708 - accuracy: 0.6303\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 130724.5181 - accuracy: 0.5167\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 129.8673 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 57347.0860 - accuracy: 0.5283\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 14226.0508 - accuracy: 0.5778\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 58586.1418 - accuracy: 0.5322\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 627.0352 - accuracy: 0.6801\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 111402.6833 - accuracy: 0.5143\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3217.3865 - accuracy: 0.5662\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 65897.9243 - accuracy: 0.5168\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2102.0461 - accuracy: 0.5795\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 45499.9443 - accuracy: 0.5126\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3355.5503 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 66467.2234 - accuracy: 0.5204\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2551.2903 - accuracy: 0.5931\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 63627.0788 - accuracy: 0.5256\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6657.6484 - accuracy: 0.6445\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 71134.4940 - accuracy: 0.5145\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 6146.5093 - accuracy: 0.5662\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 52579.9746 - accuracy: 0.5117\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2790.7095 - accuracy: 0.6354\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 47908.0694 - accuracy: 0.5156\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 10393.4590 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 59584.0000 - accuracy: 0.5058\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 10420.4814 - accuracy: 0.5778\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 70332.8078 - accuracy: 0.5012\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5229.9604 - accuracy: 0.6784\n",
      "946/946 [==============================] - 13s 14ms/step - loss: 106611.8985 - accuracy: 0.5115\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6714.7666 - accuracy: 0.5451\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 82302.2812 - accuracy: 0.5192\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 12383.9346 - accuracy: 0.5635\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 99619.0759 - accuracy: 0.5167\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1360.8246 - accuracy: 0.5994\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 139799.6236 - accuracy: 0.5204\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1302.4601 - accuracy: 0.5778\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 87618.3499 - accuracy: 0.5204\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5517.2520 - accuracy: 0.6433\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 52396.0091 - accuracy: 0.5169\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1094.3374 - accuracy: 0.5662\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 91745.3059 - accuracy: 0.5186\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 16023.9658 - accuracy: 0.5635\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 49552.3919 - accuracy: 0.5127\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9293.9326 - accuracy: 0.4784\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 66517.8105 - accuracy: 0.5228\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3794.8821 - accuracy: 0.5774\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 56368.3539 - accuracy: 0.5192\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5602.2808 - accuracy: 0.6322\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 61194.0388 - accuracy: 0.5048\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8886.6514 - accuracy: 0.5201\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 48398.1300 - accuracy: 0.5155\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1023.9650 - accuracy: 0.6413\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 55101.0171 - accuracy: 0.5179\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 496.6534 - accuracy: 0.6671\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 60902.7140 - accuracy: 0.5177\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 30.0888 - accuracy: 0.6227\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 48432.2859 - accuracy: 0.5112\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5334.2544 - accuracy: 0.5700\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 102704.6493 - accuracy: 0.5186\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1963.4780 - accuracy: 0.6686\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 39379.2480 - accuracy: 0.5072\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 10447.4688 - accuracy: 0.5635\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 68500.6389 - accuracy: 0.5144\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2397.4517 - accuracy: 0.6290\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 71232.9560 - accuracy: 0.5200\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1076.8616 - accuracy: 0.6857\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 99960.9231 - accuracy: 0.5155\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6282.5635 - accuracy: 0.6716\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 99041.3571 - accuracy: 0.5211\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2650.1643 - accuracy: 0.6145\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 53379.2567 - accuracy: 0.5266\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1008.5947 - accuracy: 0.5854\n",
      "946/946 [==============================] - 13s 14ms/step - loss: 73674.8288 - accuracy: 0.5172\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 7278.1792 - accuracy: 0.5592\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 68813.2363 - accuracy: 0.5284\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1753.5649 - accuracy: 0.6053\n",
      "946/946 [==============================] - 15s 15ms/step - loss: 70876.0044 - accuracy: 0.5213\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 751.7258 - accuracy: 0.4435\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 65039.7260 - accuracy: 0.5101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 1s 3ms/step - loss: 2827.5835 - accuracy: 0.5434\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 45789.1022 - accuracy: 0.5156\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 4137.4565 - accuracy: 0.6383\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 43352.2897 - accuracy: 0.5152\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3527.4597 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 64617.4371 - accuracy: 0.5112\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1470.5704 - accuracy: 0.6387\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 69046.2460 - accuracy: 0.5057\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1047.7720 - accuracy: 0.5565\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 127297.5145 - accuracy: 0.5255\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 12539.4014 - accuracy: 0.5662\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 71331.8696 - accuracy: 0.5113\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8681.0254 - accuracy: 0.5635\n",
      "946/946 [==============================] - 13s 14ms/step - loss: 64295.4298 - accuracy: 0.5162\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8785.7412 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 55007.2182 - accuracy: 0.5316\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 3037.8420 - accuracy: 0.4281\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 91836.1766 - accuracy: 0.5136\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9484.8984 - accuracy: 0.4401\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 48188.3828 - accuracy: 0.5086\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 1491.9509 - accuracy: 0.6039\n",
      "946/946 [==============================] - 13s 14ms/step - loss: 81141.8784 - accuracy: 0.5156\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 4660.9688 - accuracy: 0.5956\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 65089.6666 - accuracy: 0.5233\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1045.4139 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 64853.3199 - accuracy: 0.5122\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2501.7366 - accuracy: 0.5778\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 114075.8843 - accuracy: 0.5207\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8840.2178 - accuracy: 0.5696\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 68819.6884 - accuracy: 0.5181\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 13913.0732 - accuracy: 0.5472\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 40921.5617 - accuracy: 0.5215\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 526.3610 - accuracy: 0.6815\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 72863.3229 - accuracy: 0.5235\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 737.1522 - accuracy: 0.6197\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 51082.1009 - accuracy: 0.5226\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 22966.5273 - accuracy: 0.5778\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 68171.9123 - accuracy: 0.5112\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1448.5392 - accuracy: 0.6792\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 55042.2473 - accuracy: 0.5207\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2507.0437 - accuracy: 0.6234\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 71673.0741 - accuracy: 0.5176\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6296.6855 - accuracy: 0.5635\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 66646.8740 - accuracy: 0.5185\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3484.4382 - accuracy: 0.5981\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 64761.3337 - accuracy: 0.5004\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 5850.1567 - accuracy: 0.5778\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 50434.1826 - accuracy: 0.5171\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2241.0110 - accuracy: 0.5565\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 39002.2447 - accuracy: 0.5128\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1671.5063 - accuracy: 0.4985\n",
      "946/946 [==============================] - 14s 15ms/step - loss: 64696.6174 - accuracy: 0.5196\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2119.5205 - accuracy: 0.6117\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 75742.3451 - accuracy: 0.5213\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1619.4224 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 14ms/step - loss: 79062.0546 - accuracy: 0.5320\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2284.5532 - accuracy: 0.6074\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 48410.7389 - accuracy: 0.5251\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 335.9037 - accuracy: 0.6276\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 65492.8456 - accuracy: 0.5324\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3739.8811 - accuracy: 0.4338\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 85453.4672 - accuracy: 0.5139\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3332.1074 - accuracy: 0.6574\n",
      "946/946 [==============================] - 13s 14ms/step - loss: 61872.9388 - accuracy: 0.5126\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 12477.4619 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 83280.5106 - accuracy: 0.5341\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 11771.7510 - accuracy: 0.5778\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 50648.4328 - accuracy: 0.5160\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2251.3345 - accuracy: 0.5070\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 59732.6495 - accuracy: 0.5277\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6841.2690 - accuracy: 0.5662\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 49370.3019 - accuracy: 0.5260\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 9484.2529 - accuracy: 0.5635\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 54587.5453 - accuracy: 0.5038\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2925.2102 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 56490.2626 - accuracy: 0.5002\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2618.6133 - accuracy: 0.5994\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 69635.1629 - accuracy: 0.5282\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2819.9194 - accuracy: 0.5565\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 72981.2813 - accuracy: 0.5154\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2395.7324 - accuracy: 0.5662\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 46376.2729 - accuracy: 0.5044\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 33.9925 - accuracy: 0.6561\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 59139.3428 - accuracy: 0.5236\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 299.3140 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 60810.4505 - accuracy: 0.5087\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1021.7109 - accuracy: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946/946 [==============================] - 13s 13ms/step - loss: 88299.8175 - accuracy: 0.5139\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 8099.1826 - accuracy: 0.6179\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 64656.1321 - accuracy: 0.5266\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2296.7090 - accuracy: 0.5916\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 68948.9765 - accuracy: 0.5160\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1561.7290 - accuracy: 0.6341\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 49924.0341 - accuracy: 0.5061\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 2259.3999 - accuracy: 0.5592\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 91187.7690 - accuracy: 0.5104\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3285.0015 - accuracy: 0.4894\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 46149.3031 - accuracy: 0.5229\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 4810.6929 - accuracy: 0.5565\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 94623.6487 - accuracy: 0.5148\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 3442.2576 - accuracy: 0.4913\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 47176.4547 - accuracy: 0.5084\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 3269.3748 - accuracy: 0.5635\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 62974.5596 - accuracy: 0.5278\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 8879.5576 - accuracy: 0.6058\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 60824.3015 - accuracy: 0.5190\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 23097.3633 - accuracy: 0.5778\n",
      "473/473 [==============================] - 9s 17ms/step - loss: 68499.1737 - accuracy: 0.5019\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 9299.8955 - accuracy: 0.5565\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 58340.8867 - accuracy: 0.5142 \n",
      "119/119 [==============================] - 1s 4ms/step - loss: 23208.4004 - accuracy: 0.5662\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 59676.2892 - accuracy: 0.5075\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 1631.6729 - accuracy: 0.6844\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 56700.4224 - accuracy: 0.5104\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3960.1416 - accuracy: 0.5499\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 57760.1915 - accuracy: 0.5111\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 10436.2871 - accuracy: 0.5761\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 49443.9468 - accuracy: 0.5119\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 1510.4053 - accuracy: 0.5696\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 77038.5259 - accuracy: 0.4945\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 13480.5869 - accuracy: 0.4338\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 63180.5969 - accuracy: 0.5125\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7217.5195 - accuracy: 0.4670\n",
      "473/473 [==============================] - 8s 14ms/step - loss: 46406.6982 - accuracy: 0.5135\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4061.3042 - accuracy: 0.6168\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 52674.0398 - accuracy: 0.5065\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 2176.8816 - accuracy: 0.6882\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 49541.7052 - accuracy: 0.5091\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 1414.0786 - accuracy: 0.5565\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 76450.6302 - accuracy: 0.5117\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4163.5508 - accuracy: 0.5328\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 77417.6446 - accuracy: 0.5364\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 12371.6367 - accuracy: 0.6024\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 129682.7805 - accuracy: 0.5199\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 4868.8638 - accuracy: 0.5592\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 55121.8168 - accuracy: 0.5078\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6178.3765 - accuracy: 0.5778\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 74471.9563 - accuracy: 0.5112\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 2184.5537 - accuracy: 0.6492\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 44301.5966 - accuracy: 0.5215\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 5085.3350 - accuracy: 0.5637\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 66654.6868 - accuracy: 0.5058\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 605.2479 - accuracy: 0.6565\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 46955.1113 - accuracy: 0.5070\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14559.5283 - accuracy: 0.4666\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 62196.3428 - accuracy: 0.5065\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 2613.5198 - accuracy: 0.5918\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 53624.6195 - accuracy: 0.5081\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 15827.5840 - accuracy: 0.6005\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 65663.3720 - accuracy: 0.5246\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3963.9302 - accuracy: 0.5662\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 57988.8697 - accuracy: 0.5164\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4605.0386 - accuracy: 0.5635\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 65533.2371 - accuracy: 0.5114\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8741.4902 - accuracy: 0.5592\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 68956.1935 - accuracy: 0.4944\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 5114.0825 - accuracy: 0.5808\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 55583.1200 - accuracy: 0.5179\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4832.2471 - accuracy: 0.6479\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 65734.0842 - accuracy: 0.5085\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 18015.7031 - accuracy: 0.5662\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 42504.0187 - accuracy: 0.5215\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 21560.2871 - accuracy: 0.5635\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 44259.4568 - accuracy: 0.4968\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7514.6626 - accuracy: 0.5592\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 51463.9950 - accuracy: 0.5108\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3507.5886 - accuracy: 0.6819\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 61010.6045 - accuracy: 0.5156\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 4466.5127 - accuracy: 0.6280\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 74646.3462 - accuracy: 0.5103\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 1121.7026 - accuracy: 0.6648\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 81039.3558 - accuracy: 0.5159\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 2048.4834 - accuracy: 0.5635\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 51519.5522 - accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 3ms/step - loss: 4176.9863 - accuracy: 0.5592\n",
      "473/473 [==============================] - 8s 16ms/step - loss: 57013.7684 - accuracy: 0.5064\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4076.4209 - accuracy: 0.6506\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 76046.3816 - accuracy: 0.5130\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7455.1538 - accuracy: 0.4892\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 56474.6787 - accuracy: 0.5135\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 11978.3311 - accuracy: 0.5662\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 74376.7626 - accuracy: 0.5178\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 2089.8091 - accuracy: 0.6629\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 52399.9412 - accuracy: 0.5174\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 3828.8984 - accuracy: 0.5639\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 70180.7221 - accuracy: 0.5042\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4338.0869 - accuracy: 0.5998\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 57167.9352 - accuracy: 0.5187\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3677.7817 - accuracy: 0.5980\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 69896.9332 - accuracy: 0.5148\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 18376.0391 - accuracy: 0.5662\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 64144.1783 - accuracy: 0.4963\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 2094.0261 - accuracy: 0.6201\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 49415.3274 - accuracy: 0.5094\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 15626.4619 - accuracy: 0.5838\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 60180.1243 - accuracy: 0.5180\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 12987.2939 - accuracy: 0.5778\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 63464.3940 - accuracy: 0.4974\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 6734.1216 - accuracy: 0.5565\n",
      "473/473 [==============================] - 8s 16ms/step - loss: 86420.1641 - accuracy: 0.5135\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 2144.3711 - accuracy: 0.5662\n",
      "473/473 [==============================] - 9s 17ms/step - loss: 65349.4862 - accuracy: 0.5089\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 351.6844 - accuracy: 0.6392\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 51129.6778 - accuracy: 0.5051\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 2095.7009 - accuracy: 0.5901\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 48001.5787 - accuracy: 0.5025\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27199.1328 - accuracy: 0.5778\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 46853.1605 - accuracy: 0.5135\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 4207.2002 - accuracy: 0.6784\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 79578.1648 - accuracy: 0.5122\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 807.9260 - accuracy: 0.5806\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 66407.0118 - accuracy: 0.5008\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8656.2627 - accuracy: 0.5635\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 55090.1943 - accuracy: 0.5090\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3397.8052 - accuracy: 0.5592\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 72791.1195 - accuracy: 0.5151\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 522.6038 - accuracy: 0.6840\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 47704.5553 - accuracy: 0.5021\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 13308.6133 - accuracy: 0.5624\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 109466.6668 - accuracy: 0.5170\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 1612.6266 - accuracy: 0.5662\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 63429.9172 - accuracy: 0.5027\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 4592.9360 - accuracy: 0.4365\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 96180.2654 - accuracy: 0.5084\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 1329.0138 - accuracy: 0.6265\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 76284.5680 - accuracy: 0.5126\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3199.7163 - accuracy: 0.6641\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 69574.2573 - accuracy: 0.5026\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 3732.2471 - accuracy: 0.6483\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 67613.8338 - accuracy: 0.5275\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 1133.5347 - accuracy: 0.6703\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 51631.2775 - accuracy: 0.5269\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 6051.8955 - accuracy: 0.6011\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 57008.0097 - accuracy: 0.5164\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 1670.8057 - accuracy: 0.6074\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 118537.9754 - accuracy: 0.5109\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 2249.8186 - accuracy: 0.5778\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 127481.7135 - accuracy: 0.5060\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 2895.7800 - accuracy: 0.5565\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 43434.0177 - accuracy: 0.4965\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 6419.2017 - accuracy: 0.5793\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 54680.9643 - accuracy: 0.5140\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 6385.5879 - accuracy: 0.5635\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 60187.3468 - accuracy: 0.5201\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6642.0923 - accuracy: 0.5592\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 48622.5750 - accuracy: 0.5241\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 985.7071 - accuracy: 0.6853\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 66655.5930 - accuracy: 0.5087\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7144.5562 - accuracy: 0.5565\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 59959.8083 - accuracy: 0.5059\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 8187.6587 - accuracy: 0.5662\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 55322.9899 - accuracy: 0.5237\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 14920.8223 - accuracy: 0.5635\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 46928.4542 - accuracy: 0.5188\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 15473.9473 - accuracy: 0.5592\n",
      "473/473 [==============================] - 8s 14ms/step - loss: 45488.2083 - accuracy: 0.5038\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 4727.5083 - accuracy: 0.5660\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 61643.7764 - accuracy: 0.5083\n",
      "119/119 [==============================] - 1s 3ms/step - loss: 1827.0764 - accuracy: 0.5565\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 59909.3966 - accuracy: 0.5054\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 940.5311 - accuracy: 0.6297\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 63092.9068 - accuracy: 0.5106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 4ms/step - loss: 5567.6724 - accuracy: 0.5613\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 65910.5280 - accuracy: 0.5157\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7789.2100 - accuracy: 0.6248\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 77758.0733 - accuracy: 0.5168\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 5780.3403 - accuracy: 0.5884\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 59099.0491 - accuracy: 0.5196\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 173.0303 - accuracy: 0.6242\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 59871.4048 - accuracy: 0.5128\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 992.9172 - accuracy: 0.5662\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 68395.9030 - accuracy: 0.5040\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 6785.7314 - accuracy: 0.5541\n",
      "473/473 [==============================] - 7s 15ms/step - loss: 54031.9242 - accuracy: 0.5278\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 2691.7573 - accuracy: 0.6074\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 70716.0034 - accuracy: 0.5143\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 12316.7920 - accuracy: 0.5778\n",
      "473/473 [==============================] - 8s 15ms/step - loss: 53323.2610 - accuracy: 0.5069\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 6468.7539 - accuracy: 0.5971\n",
      "473/473 [==============================] - 7s 14ms/step - loss: 56284.8134 - accuracy: 0.5129\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4038.9480 - accuracy: 0.5662\n",
      "1182/1182 [==============================] - 16s 13ms/step - loss: 47059.9853 - accuracy: 0.5260\n",
      "{'batch_size': 10, 'init': 'normal', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "507/507 [==============================] - 2s 3ms/step - loss: 1210.7219 - accuracy: 0.6383\n",
      "dnn: 0.6383020877838135\n"
     ]
    }
   ],
   "source": [
    "DNN = dnn(x_train, y_train, x_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/violeta/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/home/violeta/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/violeta/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.83%, Logloss: nan\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 66736.9343 - accuracy: 0.5185\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 809.3361 - accuracy: 0.6184\n",
      "946/946 [==============================] - 13s 13ms/step - loss: 82213.6613 - accuracy: 0.5187\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2984.7588 - accuracy: 0.6637\n",
      "946/946 [==============================] - 15s 15ms/step - loss: 68178.9315 - accuracy: 0.5316\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 2979.4426 - accuracy: 0.6536\n",
      "946/946 [==============================] - 16s 16ms/step - loss: 53726.5693 - accuracy: 0.5201\n",
      "237/237 [==============================] - 1s 4ms/step - loss: 6839.9321 - accuracy: 0.5861\n",
      "946/946 [==============================] - 14s 14ms/step - loss: 59435.6535 - accuracy: 0.5161\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 6237.6113 - accuracy: 0.4951\n",
      "0.6033909738063812\n"
     ]
    }
   ],
   "source": [
    "test_model(DNN, x_validation, y_validation)\n",
    "cross_val(DNN, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERCEPTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x_train, y_train, x_validation, y_validation):\n",
    "    perceptron = Perceptron(tol=1e-3, random_state=0)\n",
    "    params_perc = {'alpha': [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3]}\n",
    "    per_gs = model_selection.GridSearchCV(perceptron, params_perc, cv=5)\n",
    "    per_gs.fit(x_train, y_train)\n",
    "    per_best = per_gs.best_estimator_\n",
    "    print(per_gs.best_params_)\n",
    "    print('perceptron: {}'.format(per_best.score(x_validation, y_validation)))\n",
    "    return per_gs\n",
    "\n",
    "def multi_perceptron(x_train, y_train, x_validation, y_validation):\n",
    "    mult_perceptron = MLPClassifier(tol=1e-3, random_state=0)\n",
    "    params_mult_perc =  {'hidden_layer_sizes': [(10,30,10),(20,)],'activation': ['tanh', 'relu'],'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive'],\n",
    "    }\n",
    "    mul_per_gs = model_selection.GridSearchCV(mult_perceptron, params_mult_perc, cv=5)\n",
    "    mul_per_gs.fit(x_train, y_train)\n",
    "    mul_per_best = mul_per_gs.best_estimator_\n",
    "    print(mul_per_gs.best_params_)\n",
    "    print('multi perceptron: {}'.format(mul_per_best.score(x_validation, y_validation)))\n",
    "    return mul_per_best\n",
    "\n",
    "def multi_perceptron_2(x_train, y_train, x_validation, y_validation):\n",
    "    mult_perceptron_2 = MLPRegressor()\n",
    "    params_mult_perc_2 = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (20,)],'activation': ['relu','tanh','logistic'],\n",
    "          'alpha': [0.0001, 0.05],'learning_rate': ['constant','adaptive'],\n",
    "          'solver': ['sgd', 'adam']}\n",
    "    mul_per_gs_2 = model_selection.GridSearchCV(mult_perceptron_2, params_mult_perc_2, cv=5)\n",
    "    mul_per_gs_2.fit(x_train, y_train)\n",
    "    mul_per_best_2 = mul_per_gs_2.best_estimator_\n",
    "    print(mul_per_gs_2.best_params_)\n",
    "    print('multi perceptron 2: {}'.format(mul_per_best_2.score(x_validation, y_validation)))\n",
    "    return mul_per_gs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (20,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "multi perceptron: 0.6400789733464955\n",
      "Accuracy: 64.01%, Logloss: 0.63\n",
      "0.6810810056045937\n"
     ]
    }
   ],
   "source": [
    "PERC = multi_perceptron(x_train, y_train, x_validation, y_validation)\n",
    "test_model(PERC, x_validation, y_validation)\n",
    "cross_val(PERC, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
